{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the input data\n",
    "\n",
    "from utils import plot_loss, encoder_files_to_tensors, normalize_params\n",
    "from utils import sample_files\n",
    "import time\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import yaml\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "data_dir = '/eos/kiliakis/tomo_data/datasets'\n",
    "# data_dir = './tomo_data/datasets'\n",
    "\n",
    "# Data specific\n",
    "IMG_OUTPUT_SIZE = 128\n",
    "latent_dim = 7  # 6 + the new VrfSPS\n",
    "\n",
    "# Keep only a small percentage of the entire dataset\n",
    "# for faster testing.\n",
    "dataset_keep_percent = 0.001\n",
    "\n",
    "# Training: 338900\n",
    "# Validation: 59136 (338901 - 399036)\n",
    "# Testing: 71526 (398037 - 469562)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize train/ test / validation paths\n",
    "ML_dir = os.path.join(data_dir, 'ML_data')\n",
    "TRAINING_PATH = os.path.join(ML_dir, 'TRAINING')\n",
    "assert os.path.exists(TRAINING_PATH)\n",
    "\n",
    "# VALIDATION_PATH = os.path.join(ML_dir, 'VALIDATION')\n",
    "# assert os.path.exists(VALIDATION_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the datasets\n",
    "# First the training data\n",
    "file_names = sample_files(TRAINING_PATH, dataset_keep_percent, keep_every=51)\n",
    "# print(sorted(file_names)[:10])\n",
    "\n",
    "# read input, divide in features/ label, create tensors\n",
    "x_train, y_train = encoder_files_to_tensors(file_names, normalize=False)\n",
    "\n",
    "# # Then the validation data\n",
    "# files = glob.glob(VALIDATION_PATH + '/*.pk')\n",
    "# files = files[:int(len(files) * dataset_keep_percent)]\n",
    "\n",
    "# # Shuffle them\n",
    "# np.random.shuffle(files)\n",
    "# # read input, divide in features/ label, create tensors\n",
    "# x_valid, y_valid = encoder_files_to_tensors(files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# plot some of the outputs\n",
    "\n",
    "nrows = 2\n",
    "# Get nrows * nrows random images\n",
    "# sample = np.random.choice(np.arange(len(x_train)),\n",
    "#                           size=nrows * nrows, replace=False)\n",
    "\n",
    "# samples_X = tf.gather(x_train, sample)\n",
    "# samples_y = tf.gather(y_train, sample)\n",
    "\n",
    "samples_X = x_train[:nrows*nrows]\n",
    "samples_y = y_train[:nrows*nrows]\n",
    "\n",
    "\n",
    "# Create 3x3 grid of figures\n",
    "fig, axes = plt.subplots(ncols=nrows, nrows=nrows, figsize=(12, 12))\n",
    "axes = np.ravel(axes)\n",
    "for i in range(len(axes)):\n",
    "    ax = axes[i]\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    # show the image\n",
    "    ax.imshow(samples_X[i], cmap='jet')\n",
    "    # Set the label\n",
    "    title = ','.join([f'{num:.1f}' for num in samples_y[i]])\n",
    "    ax.set_title(f'{title}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "nrows = 1\n",
    "# Get nrows * nrows random images\n",
    "sample = np.random.choice(np.arange(len(x_train)),\n",
    "                          size=nrows * nrows, replace=False)\n",
    "\n",
    "samples_X = tf.gather(x_train, sample)\n",
    "samples_y = tf.gather(y_train, sample)\n",
    "\n",
    "# Create 3x3 grid of figures\n",
    "fig, axes = plt.subplots(ncols=nrows, nrows=nrows, figsize=(8, 8))\n",
    "axes = np.ravel(axes)\n",
    "for i in range(len(axes)):\n",
    "    ax = axes[i]\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    # show the image\n",
    "    ax.imshow(samples_X[i][14:-14, 14:-14], cmap='jet')\n",
    "    # Set the label\n",
    "    # title = ','.join([f'{num:.1f}' for num in samples_y[i]])\n",
    "    print(samples_y[i])\n",
    "    # ax.set_title(f'{title}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_x_train = x_train.numpy().mean(axis=0)\n",
    "cropped_mean = mean_x_train[14:-14, 14:-14]\n",
    "# Create 3x3 grid of figures\n",
    "fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(12, 12))\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "# show the image\n",
    "ax.imshow(cropped_mean, cmap='jet')\n",
    "# Set the label\n",
    "ax.set_title(f'Mean of all x_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "# y_train = y_train.numpy()\n",
    "std_scaler = StandardScaler().fit(y_train)\n",
    "min_max_scaler = MinMaxScaler().fit(y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('Mean: ', std_scaler.mean_)\n",
    "print('STD: ', std_scaler.scale_)\n",
    "print('Min: ', min_max_scaler.data_min_)\n",
    "print('Max: ', min_max_scaler.data_max_)\n",
    "\n",
    "# print(tf.reduce_mean(y_train, 0))\n",
    "# print(tf.math.reduce_std(y_train, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_max_norm_data = min_max_scaler.transform(y_train)\n",
    "# std_norm_data = std_scaler.transform(y_train)\n",
    "min_max_norm_data = normalize_params(\n",
    "    y_train[:, 0], y_train[:, 1], y_train[:, 2],\n",
    "    y_train[:, 3], y_train[:, 4], y_train[:, 5], \n",
    "    y_train[:, 6], normalization='minmax')\n",
    "\n",
    "std_norm_data = normalize_params(\n",
    "    y_train[:, 0], y_train[:, 1], y_train[:, 2],\n",
    "    y_train[:, 3], y_train[:, 4], y_train[:, 5], \n",
    "    y_train[:, 6], normalization='std')\n",
    "\n",
    "default_norm_data = normalize_params(\n",
    "    y_train[:, 0], y_train[:, 1], y_train[:, 2],\n",
    "    y_train[:, 3], y_train[:, 4], y_train[:, 5], \n",
    "    y_train[:, 6], normalization='default')\n",
    "\n",
    "\n",
    "# Now plot the data distribution\n",
    "var_names = ['phase_error', 'energy_error',\n",
    "             'bunch_length', 'intensity', 'V_rf', 'mu', 'Vrf_SPS']\n",
    "fig, axes = plt.subplots(ncols=4, nrows=len(var_names), sharex=False,\n",
    "                         sharey=True, figsize=(16, 16))\n",
    "for i, name in enumerate(var_names):\n",
    "    hist, edges = np.histogram(min_max_norm_data[i], bins=20, density=False)\n",
    "    hist = hist / len(y_train[:, i])\n",
    "    print(name+'-min_max', edges)\n",
    "    ax = axes[i][0]\n",
    "    plt.sca(ax)\n",
    "    plt.bar(np.arange(len(hist)), hist, width=0.8)\n",
    "    plt.title(name + '-min_max')\n",
    "    # edges = [f'{e:.4f}' for e in edges]\n",
    "    plt.xticks(np.arange(len(hist))[[0,-1]], edges[[0,-1]])\n",
    "    plt.xlabel('Bin')\n",
    "    plt.ylabel('Density')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    hist, edges = np.histogram(std_norm_data[i], bins=20, density=False)\n",
    "    hist = hist / len(y_train[:, i])\n",
    "    print(name+'-std', edges)\n",
    "    ax = axes[i][1]\n",
    "    plt.sca(ax)\n",
    "    plt.bar(np.arange(len(hist)), hist, width=0.8)\n",
    "    plt.title(name + '-std')\n",
    "    # edges = [f'{e:.4f}' for e in edges]\n",
    "    plt.xticks(np.arange(len(hist))[[0,-1]], edges[[0,-1]])\n",
    "    plt.xlabel('Bin')\n",
    "    plt.ylabel('Density')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    hist, edges = np.histogram(default_norm_data[i], bins=20, density=False)\n",
    "    hist = hist / len(y_train[:, i])\n",
    "    print(name+'-def', edges)\n",
    "    ax = axes[i][2]\n",
    "    plt.sca(ax)\n",
    "    plt.bar(np.arange(len(hist)), hist, width=0.8)\n",
    "    plt.title(name + '-def')\n",
    "    # edges = [f'{e:.4f}' for e in edges]\n",
    "    plt.xticks(np.arange(len(hist))[[0,-1]], edges[[0,-1]])\n",
    "    plt.xlabel('Bin')\n",
    "    plt.ylabel('Density')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    hist, edges = np.histogram(y_train[:, i], bins=20, density=False)\n",
    "    hist = hist / len(y_train[:, i])\n",
    "    print(name+'-unorm', edges)\n",
    "    ax = axes[i][3]\n",
    "    plt.sca(ax)\n",
    "    plt.bar(np.arange(len(hist)), hist, width=0.8)\n",
    "    plt.title(name + '-unorm')\n",
    "    # edges = [f'{e:.4f}' for e in edges]\n",
    "    plt.xticks(np.arange(len(hist))[[0,-1]], edges[[0,-1]])\n",
    "    plt.xlabel('Bin')\n",
    "    plt.ylabel('Density')\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# plot some of the outputs\n",
    "\n",
    "nrows = 3\n",
    "# Get nrows * nrows random images\n",
    "sample = np.random.choice(np.arange(len(x_train)),\n",
    "                          size=nrows * nrows, replace=False)\n",
    "\n",
    "samples_X = tf.gather(x_train, sample)\n",
    "samples_y = tf.gather(y_train, sample)\n",
    "\n",
    "# Create 3x3 grid of figures\n",
    "fig, axes = plt.subplots(ncols=nrows, nrows=nrows, figsize=(12, 12))\n",
    "axes = np.ravel(axes)\n",
    "for i in range(len(axes)):\n",
    "    ax = axes[i]\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    # show the image\n",
    "    ax.imshow(samples_X[i, 14:-14, 14:-14], cmap='jet')\n",
    "    # Set the label\n",
    "    title = ','.join([f'{num:.1f}' for num in samples_y[i]])\n",
    "    ax.set_title(f'{title}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For the decoder part\n",
    "from utils import decoder_files_to_tensors\n",
    "\n",
    "# read input, divide in features/ label, create tensors\n",
    "x_train, y_train = decoder_files_to_tensors(file_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# plot some of the outputs\n",
    "\n",
    "nrows = 1\n",
    "# Get nrows * nrows random images\n",
    "sample = np.random.choice(np.arange(len(y_train)),\n",
    "                          size=nrows, replace=False)\n",
    "\n",
    "samples_real = tf.gather(y_train, sample)\n",
    "\n",
    "# Create 3x3 grid of figures\n",
    "fig, axes = plt.subplots(ncols=nrows, nrows=nrows, figsize=(nrows*8, nrows*8))\n",
    "axes = np.ravel(axes)\n",
    "for i in range(nrows):\n",
    "    ax = axes[i]\n",
    "    plt.sca(ax)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    # show the image\n",
    "    ax.imshow(samples_real[i][14:-14, 14:-14], cmap='jet')\n",
    "    # Set the label\n",
    "    # title = ','.join([f'{num:.1f}' for num in samples_X[i]])\n",
    "    ax.set_title(f'True')\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# plot some of the outputs\n",
    "\n",
    "nrows = 5\n",
    "# Get nrows * nrows random images\n",
    "sample = np.random.choice(np.arange(len(y_test)),\n",
    "                          size=nrows, replace=False)\n",
    "\n",
    "samples_real = y_test[sample]\n",
    "samples_pred = test_pred[sample]\n",
    "\n",
    "# Create 3x3 grid of figures\n",
    "fig, axes = plt.subplots(ncols=3, nrows=nrows, figsize=(12, 20))\n",
    "# axes = np.ravel(axes)\n",
    "for i in range(nrows):\n",
    "    ax = axes[i][0]\n",
    "    plt.sca(ax)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    # show the image\n",
    "    ax.imshow(samples_real[i]+1, cmap='jet', vmin=0, vmax=2)\n",
    "    # Set the label\n",
    "    # title = ','.join([f'{num:.1f}' for num in samples_X[i]])\n",
    "    ax.set_title(f'True')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    ax = axes[i][1]\n",
    "    plt.sca(ax)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    # show the image\n",
    "    ax.imshow(samples_pred[i]+1, cmap='jet', vmin=0, vmax=2)\n",
    "    # Set the label\n",
    "    # title = ','.join([f'{num:.1f}' for num in samples_X[i]])\n",
    "    ax.set_title(f'Predicted')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    ax = axes[i][2]\n",
    "    plt.sca(ax)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    # show the image\n",
    "    plt.imshow(np.abs(samples_real[i] -\n",
    "                      samples_pred[i]), cmap='jet', vmin=0, vmax=2,\n",
    "               aspect='auto')\n",
    "    plt.colorbar()\n",
    "    # Set the label\n",
    "    # title = ','.join([f'{num:.1f}' for num in samples_X[i]])\n",
    "    ax.set_title(f'Diff')\n",
    "    plt.tight_layout()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "79ab8fd01a8cec42884b8b2a5d7fb4751c5402d97e9e61d151ed5c6a6352873c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
