{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 15:29:46.988973: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-08 15:29:47.246736: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-08 15:29:47.292971: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/kiliakis/install/lib:/usr/lib/x86_64-linux-gnu\n",
      "2022-11-08 15:29:47.292983: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-11-08 15:29:47.327604: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-08 15:29:48.009364: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/kiliakis/install/lib:/usr/lib/x86_64-linux-gnu\n",
      "2022-11-08 15:29:48.009426: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/kiliakis/install/lib:/usr/lib/x86_64-linux-gnu\n",
      "2022-11-08 15:29:48.009430: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# Inspect the input data\n",
    "\n",
    "from utils import plot_loss, encoder_files_to_tensors, normalize_params\n",
    "from utils import sample_files\n",
    "import time\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import yaml\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "# data_dir = '/eos/kiliakis/tomo_data/datasets'\n",
    "data_dir = './tomo_data/datasets'\n",
    "\n",
    "# Data specific\n",
    "IMG_OUTPUT_SIZE = 128\n",
    "latent_dim = 7  # 6 + the new VrfSPS\n",
    "\n",
    "# Keep only a small percentage of the entire dataset\n",
    "# for faster testing.\n",
    "dataset_keep_percent = 0.001\n",
    "\n",
    "# Training: 338900\n",
    "# Validation: 59136 (338901 - 399036)\n",
    "# Testing: 71526 (398037 - 469562)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize train/ test / validation paths\n",
    "ML_dir = os.path.join(data_dir, 'ML_data')\n",
    "TRAINING_PATH = os.path.join(ML_dir, 'TRAINING')\n",
    "assert os.path.exists(TRAINING_PATH)\n",
    "\n",
    "VALIDATION_PATH = os.path.join(ML_dir, 'VALIDATION')\n",
    "assert os.path.exists(VALIDATION_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = sample_files(VALIDATION_PATH, dataset_keep_percent, keep_every=51)\n",
    "file_name = file_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phEr-10_enEr-12_bl1.52e-09_int1.55e+11_Vrf4.7_mu1.8_VrfSPS6.7\n"
     ]
    }
   ],
   "source": [
    "eos = '/eos/user/k/kiliakis/'\n",
    "simulations_dir = os.path.join(eos, 'tomo_data/results_tomo')\n",
    "all_sim_dirs = os.listdir(simulations_dir)\n",
    "fn = all_sim_dirs[0]\n",
    "print(fn)\n",
    "# paramsDict, PS_imgs, sel_turns, E_img, T_img, PS_img_dec = \\\n",
    "#     extract_data_Fromfolder(fn, simulations_dir, IMG_OUTPUT_SIZE, zeropad,\n",
    "#                             start_turn, skipturns, version=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from utils import read_pk\n",
    "turn_num, T_img, PS, fn, params_dict = read_pk(file_name)\n",
    "print(T_img.dtype)\n",
    "print(np.max(T_img))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([128   4 149 ...  98 117  46], shape=(262723,), dtype=uint8)\n",
      "<class 'numpy.ndarray'>\n",
      "<dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "import pickle as pk\n",
    "raw = tf.io.read_file(file_name)\n",
    "image = tf.io.decode_raw(raw, tf.uint8)\n",
    "print(image)\n",
    "data = pk.loads(image)\n",
    "print(type(T_img))\n",
    "x_train, y_train = encoder_files_to_tensors(file_names, normalize='minmax')\n",
    "print(x_train.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import h5py as hp\n",
    "\n",
    "IMG_OUTPUT_SIZE = 128\n",
    "zeropad = 14\n",
    "skipturns = 3\n",
    "start_turn = 1\n",
    "\n",
    "pattern_string = 'phEr(?P<phEr>.+)_enEr(?P<enEr>.+)_bl(?P<bl>.+)_int(?P<int>.+)_Vrf(?P<Vrf>.+)_mu(?P<mu>.+)_VrfSPS(?P<VrfSPS>.+)'\n",
    "paramsDict = {k: float(v) for k, v in re.match(\n",
    "    pattern_string, fn).groupdict().items()}\n",
    "E_img = np.zeros((IMG_OUTPUT_SIZE, IMG_OUTPUT_SIZE))\n",
    "T_img = np.zeros((IMG_OUTPUT_SIZE, IMG_OUTPUT_SIZE))\n",
    "sf = hp.File(os.path.join(os.path.join(\n",
    "    simulations_dir, fn), 'saved_result.hdf5'), 'r')\n",
    "\n",
    "BunchProfiles = np.array(sf['bunchProfiles'])\n",
    "EnergyProfiles = np.array(sf['energyProfiles'])\n",
    "columns = sf['columns']\n",
    "phaseSpace_density_array = np.array(sf['phaseSpace_density_array'])\n",
    "\n",
    "# with hp.File(os.path.join(os.path.join(simulations_dir, fn), 'saved_result.hdf5'), 'r') as sf:\n",
    "#     print(sf['columns'][0][3])\n",
    "\n",
    "    # for k in sf.keys():\n",
    "    #     print(k, sf[k].shape)\n",
    "    # BunchProfiles = np.array(sf['bunchProfiles']) / \\\n",
    "    #     sf['columns'][0][3]*paramsDict['int']\n",
    "    # EnergyProfiles = np.array(\n",
    "    #     sf['energyProfiles'])/sf['columns'][0][3]*paramsDict['int']\n",
    "    # phaseSpace_density_array = np.array(sf['phaseSpace_density_array'])\n",
    "    # PS_imgs = np.zeros((IMG_OUTPUT_SIZE, IMG_OUTPUT_SIZE,\n",
    "    #                     phaseSpace_density_array.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import extract_data_Fromfolder\n",
    "paramsDict, PS_imgs, sel_turns, E_img, T_img, PS_img_dec = \\\n",
    "    extract_data_Fromfolder(fn, simulations_dir, IMG_OUTPUT_SIZE, zeropad,\n",
    "                            start_turn, skipturns, version=4)\n",
    "T_normFactor = np.max(T_img)\n",
    "T_min = np.min(T_img)\n",
    "# T_img = T_img / T_normFactor\n",
    "# for 8 bit I need to map to 0-255\n",
    "T_img_8bit = np.interp(T_img, [T_min, T_normFactor], [0, 255])\n",
    "# for 16 bit I need to map to 0-65535\n",
    "T_img_16bit = np.interp(T_img, [T_min, T_normFactor], [0, 65535])\n",
    "\n",
    "T_img_8bit = T_img_8bit.astype(np.uint8)\n",
    "T_img_16bit = T_img_16bit.astype(np.uint16)\n",
    "\n",
    "# print(np.max(T_img), np.mean(T_img))\n",
    "# print(np.max(T_img_8bit), np.mean(T_img_8bit))\n",
    "# print(np.max(T_img_16bit), np.mean(T_img_16bit))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=3, nrows=1, figsize=(15, 5))\n",
    "axes = np.ravel(axes)\n",
    "ax = axes[0]\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "# show the image\n",
    "ax.imshow(T_img[14:-14, 14:-50], cmap='jet')\n",
    "# Set the label\n",
    "title = 'T_img'\n",
    "ax.set_title(f'{title}')\n",
    "\n",
    "ax = axes[1]\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "# show the image\n",
    "ax.imshow(T_img_8bit[14:-14, 14:-50], cmap='jet')\n",
    "# Set the label\n",
    "title = 'T_img_8bit'\n",
    "ax.set_title(f'{title}')\n",
    "\n",
    "ax = axes[2]\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "# show the image\n",
    "ax.imshow(T_img_16bit, cmap='jet')\n",
    "# Set the label\n",
    "title = 'T_img_16bit'\n",
    "ax.set_title(f'{title}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the datasets\n",
    "# First the training data\n",
    "file_names = sample_files(TRAINING_PATH, dataset_keep_percent, keep_every=51)\n",
    "# print(sorted(file_names)[:10])\n",
    "\n",
    "# read input, divide in features/ label, create tensors\n",
    "x_train, y_train = encoder_files_to_tensors(file_names, normalize=False)\n",
    "\n",
    "# # Then the validation data\n",
    "# files = glob.glob(VALIDATION_PATH + '/*.pk')\n",
    "# files = files[:int(len(files) * dataset_keep_percent)]\n",
    "\n",
    "# # Shuffle them\n",
    "# np.random.shuffle(files)\n",
    "# # read input, divide in features/ label, create tensors\n",
    "# x_valid, y_valid = encoder_files_to_tensors(files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# plot some of the outputs\n",
    "\n",
    "nrows = 2\n",
    "# Get nrows * nrows random images\n",
    "# sample = np.random.choice(np.arange(len(x_train)),\n",
    "#                           size=nrows * nrows, replace=False)\n",
    "\n",
    "# samples_X = tf.gather(x_train, sample)\n",
    "# samples_y = tf.gather(y_train, sample)\n",
    "\n",
    "samples_X = x_train[:nrows*nrows]\n",
    "samples_y = y_train[:nrows*nrows]\n",
    "\n",
    "\n",
    "# Create 3x3 grid of figures\n",
    "fig, axes = plt.subplots(ncols=nrows, nrows=nrows, figsize=(12, 12))\n",
    "axes = np.ravel(axes)\n",
    "for i in range(len(axes)):\n",
    "    ax = axes[i]\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    # show the image\n",
    "    ax.imshow(samples_X[i], cmap='jet')\n",
    "    # Set the label\n",
    "    title = ','.join([f'{num:.1f}' for num in samples_y[i]])\n",
    "    ax.set_title(f'{title}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "nrows = 1\n",
    "# Get nrows * nrows random images\n",
    "sample = np.random.choice(np.arange(len(x_train)),\n",
    "                          size=nrows * nrows, replace=False)\n",
    "\n",
    "samples_X = tf.gather(x_train, sample)\n",
    "samples_y = tf.gather(y_train, sample)\n",
    "\n",
    "# Create 3x3 grid of figures\n",
    "fig, axes = plt.subplots(ncols=nrows, nrows=nrows, figsize=(8, 8))\n",
    "axes = np.ravel(axes)\n",
    "for i in range(len(axes)):\n",
    "    ax = axes[i]\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    # show the image\n",
    "    ax.imshow(samples_X[i][14:-14, 14:-14], cmap='jet')\n",
    "    # Set the label\n",
    "    # title = ','.join([f'{num:.1f}' for num in samples_y[i]])\n",
    "    print(samples_y[i])\n",
    "    # ax.set_title(f'{title}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_x_train = x_train.numpy().mean(axis=0)\n",
    "cropped_mean = mean_x_train[14:-14, 14:-14]\n",
    "# Create 3x3 grid of figures\n",
    "fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(12, 12))\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "# show the image\n",
    "ax.imshow(cropped_mean, cmap='jet')\n",
    "# Set the label\n",
    "ax.set_title(f'Mean of all x_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "# y_train = y_train.numpy()\n",
    "std_scaler = StandardScaler().fit(y_train)\n",
    "min_max_scaler = MinMaxScaler().fit(y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('Mean: ', std_scaler.mean_)\n",
    "print('STD: ', std_scaler.scale_)\n",
    "print('Min: ', min_max_scaler.data_min_)\n",
    "print('Max: ', min_max_scaler.data_max_)\n",
    "\n",
    "# print(tf.reduce_mean(y_train, 0))\n",
    "# print(tf.math.reduce_std(y_train, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_max_norm_data = min_max_scaler.transform(y_train)\n",
    "# std_norm_data = std_scaler.transform(y_train)\n",
    "min_max_norm_data = normalize_params(\n",
    "    y_train[:, 0], y_train[:, 1], y_train[:, 2],\n",
    "    y_train[:, 3], y_train[:, 4], y_train[:, 5], \n",
    "    y_train[:, 6], normalization='minmax')\n",
    "\n",
    "std_norm_data = normalize_params(\n",
    "    y_train[:, 0], y_train[:, 1], y_train[:, 2],\n",
    "    y_train[:, 3], y_train[:, 4], y_train[:, 5], \n",
    "    y_train[:, 6], normalization='std')\n",
    "\n",
    "default_norm_data = normalize_params(\n",
    "    y_train[:, 0], y_train[:, 1], y_train[:, 2],\n",
    "    y_train[:, 3], y_train[:, 4], y_train[:, 5], \n",
    "    y_train[:, 6], normalization='default')\n",
    "\n",
    "\n",
    "# Now plot the data distribution\n",
    "var_names = ['phase_error', 'energy_error',\n",
    "             'bunch_length', 'intensity', 'V_rf', 'mu', 'Vrf_SPS']\n",
    "fig, axes = plt.subplots(ncols=4, nrows=len(var_names), sharex=False,\n",
    "                         sharey=True, figsize=(16, 16))\n",
    "for i, name in enumerate(var_names):\n",
    "    hist, edges = np.histogram(min_max_norm_data[i], bins=20, density=False)\n",
    "    hist = hist / len(y_train[:, i])\n",
    "    print(name+'-min_max', edges)\n",
    "    ax = axes[i][0]\n",
    "    plt.sca(ax)\n",
    "    plt.bar(np.arange(len(hist)), hist, width=0.8)\n",
    "    plt.title(name + '-min_max')\n",
    "    # edges = [f'{e:.4f}' for e in edges]\n",
    "    plt.xticks(np.arange(len(hist))[[0,-1]], edges[[0,-1]])\n",
    "    plt.xlabel('Bin')\n",
    "    plt.ylabel('Density')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    hist, edges = np.histogram(std_norm_data[i], bins=20, density=False)\n",
    "    hist = hist / len(y_train[:, i])\n",
    "    print(name+'-std', edges)\n",
    "    ax = axes[i][1]\n",
    "    plt.sca(ax)\n",
    "    plt.bar(np.arange(len(hist)), hist, width=0.8)\n",
    "    plt.title(name + '-std')\n",
    "    # edges = [f'{e:.4f}' for e in edges]\n",
    "    plt.xticks(np.arange(len(hist))[[0,-1]], edges[[0,-1]])\n",
    "    plt.xlabel('Bin')\n",
    "    plt.ylabel('Density')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    hist, edges = np.histogram(default_norm_data[i], bins=20, density=False)\n",
    "    hist = hist / len(y_train[:, i])\n",
    "    print(name+'-def', edges)\n",
    "    ax = axes[i][2]\n",
    "    plt.sca(ax)\n",
    "    plt.bar(np.arange(len(hist)), hist, width=0.8)\n",
    "    plt.title(name + '-def')\n",
    "    # edges = [f'{e:.4f}' for e in edges]\n",
    "    plt.xticks(np.arange(len(hist))[[0,-1]], edges[[0,-1]])\n",
    "    plt.xlabel('Bin')\n",
    "    plt.ylabel('Density')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    hist, edges = np.histogram(y_train[:, i], bins=20, density=False)\n",
    "    hist = hist / len(y_train[:, i])\n",
    "    print(name+'-unorm', edges)\n",
    "    ax = axes[i][3]\n",
    "    plt.sca(ax)\n",
    "    plt.bar(np.arange(len(hist)), hist, width=0.8)\n",
    "    plt.title(name + '-unorm')\n",
    "    # edges = [f'{e:.4f}' for e in edges]\n",
    "    plt.xticks(np.arange(len(hist))[[0,-1]], edges[[0,-1]])\n",
    "    plt.xlabel('Bin')\n",
    "    plt.ylabel('Density')\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# plot some of the outputs\n",
    "\n",
    "nrows = 3\n",
    "# Get nrows * nrows random images\n",
    "sample = np.random.choice(np.arange(len(x_train)),\n",
    "                          size=nrows * nrows, replace=False)\n",
    "\n",
    "samples_X = tf.gather(x_train, sample)\n",
    "samples_y = tf.gather(y_train, sample)\n",
    "\n",
    "# Create 3x3 grid of figures\n",
    "fig, axes = plt.subplots(ncols=nrows, nrows=nrows, figsize=(12, 12))\n",
    "axes = np.ravel(axes)\n",
    "for i in range(len(axes)):\n",
    "    ax = axes[i]\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    # show the image\n",
    "    ax.imshow(samples_X[i, 14:-14, 14:-14], cmap='jet')\n",
    "    # Set the label\n",
    "    title = ','.join([f'{num:.1f}' for num in samples_y[i]])\n",
    "    ax.set_title(f'{title}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For the decoder part\n",
    "from utils import decoder_files_to_tensors\n",
    "\n",
    "# read input, divide in features/ label, create tensors\n",
    "x_train, y_train = decoder_files_to_tensors(file_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# plot some of the outputs\n",
    "\n",
    "nrows = 1\n",
    "# Get nrows * nrows random images\n",
    "sample = np.random.choice(np.arange(len(y_train)),\n",
    "                          size=nrows, replace=False)\n",
    "\n",
    "samples_real = tf.gather(y_train, sample)\n",
    "\n",
    "# Create 3x3 grid of figures\n",
    "fig, axes = plt.subplots(ncols=nrows, nrows=nrows, figsize=(nrows*8, nrows*8))\n",
    "axes = np.ravel(axes)\n",
    "for i in range(nrows):\n",
    "    ax = axes[i]\n",
    "    plt.sca(ax)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    # show the image\n",
    "    ax.imshow(samples_real[i][14:-14, 14:-14], cmap='jet')\n",
    "    # Set the label\n",
    "    # title = ','.join([f'{num:.1f}' for num in samples_X[i]])\n",
    "    ax.set_title(f'True')\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# plot some of the outputs\n",
    "\n",
    "nrows = 5\n",
    "# Get nrows * nrows random images\n",
    "sample = np.random.choice(np.arange(len(y_test)),\n",
    "                          size=nrows, replace=False)\n",
    "\n",
    "samples_real = y_test[sample]\n",
    "samples_pred = test_pred[sample]\n",
    "\n",
    "# Create 3x3 grid of figures\n",
    "fig, axes = plt.subplots(ncols=3, nrows=nrows, figsize=(12, 20))\n",
    "# axes = np.ravel(axes)\n",
    "for i in range(nrows):\n",
    "    ax = axes[i][0]\n",
    "    plt.sca(ax)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    # show the image\n",
    "    ax.imshow(samples_real[i]+1, cmap='jet', vmin=0, vmax=2)\n",
    "    # Set the label\n",
    "    # title = ','.join([f'{num:.1f}' for num in samples_X[i]])\n",
    "    ax.set_title(f'True')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    ax = axes[i][1]\n",
    "    plt.sca(ax)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    # show the image\n",
    "    ax.imshow(samples_pred[i]+1, cmap='jet', vmin=0, vmax=2)\n",
    "    # Set the label\n",
    "    # title = ','.join([f'{num:.1f}' for num in samples_X[i]])\n",
    "    ax.set_title(f'Predicted')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    ax = axes[i][2]\n",
    "    plt.sca(ax)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    # show the image\n",
    "    plt.imshow(np.abs(samples_real[i] -\n",
    "                      samples_pred[i]), cmap='jet', vmin=0, vmax=2,\n",
    "               aspect='auto')\n",
    "    plt.colorbar()\n",
    "    # Set the label\n",
    "    # title = ','.join([f'{num:.1f}' for num in samples_X[i]])\n",
    "    ax.set_title(f'Diff')\n",
    "    plt.tight_layout()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 13:09:58) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "79ab8fd01a8cec42884b8b2a5d7fb4751c5402d97e9e61d151ed5c6a6352873c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
