{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the ML model\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import time\n",
    "\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from utils import decoder_files_to_tensors, get_best_model_timestamp\n",
    "from utils import unnormalize_params, assess_decoder\n",
    "from utils import sample_files\n",
    "from models import Decoder, mse_loss_encoder, mse_loss_decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "# data_dir = '/eos/user/k/kiliakis/tomo_data/datasets_decoder_02-12-22'\n",
    "data_dir = './tomo_data/datasets_decoder_02-12-22'\n",
    "\n",
    "\n",
    "# Initialize train/ test / validation paths\n",
    "ML_dir = os.path.join(data_dir, 'ML_data')\n",
    "TESTING_PATH = os.path.join(ML_dir, 'TESTING')\n",
    "assert os.path.exists(TESTING_PATH)\n",
    "\n",
    "# First the training data\n",
    "file_names = sample_files(TESTING_PATH, 0.01, keep_every=1)\n",
    "print(len(file_names))\n",
    "import time\n",
    "start_t = time.time()\n",
    "# read input, divide in features/ label, create tensors\n",
    "x_test, y_test = decoder_files_to_tensors(file_names, normalization='minmax')\n",
    "total_time = time.time() - start_t\n",
    "print(f'Elapsed time: {total_time:.3f}, Per file: {total_time/len(file_names):.3f}')\n",
    "\n",
    "# VALIDATION_PATH = os.path.join(ML_dir, 'VALIDATION')\n",
    "# assert os.path.exists(VALIDATION_PATH)\n",
    "\n",
    "# # Then the validation data\n",
    "# files = glob.glob(VALIDATION_PATH + '/*.pk')\n",
    "\n",
    "# # Shuffle them\n",
    "# np.random.shuffle(files)\n",
    "# # read input, divide in features/ label, create tensors\n",
    "# x_valid, y_valid = decoder_files_to_tensors(files)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model to load\n",
    "timestamp = '2022_12_13_15-37-27'\n",
    "# timestamp = get_best_model_timestamp('./trials', model='dec')\n",
    "print(timestamp)\n",
    "\n",
    "# Initialize directories\n",
    "trial_dir = os.path.join('./trials/', timestamp)\n",
    "weights_dir = os.path.join(trial_dir, 'weights')\n",
    "plots_dir = os.path.join(trial_dir, 'plots')\n",
    "assert os.path.exists(weights_dir)\n",
    "os.makedirs(plots_dir, exist_ok=True)\n",
    "\n",
    "# load the model\n",
    "decoder = keras.models.load_model(os.path.join(weights_dir, 'decoder.h5'),\n",
    "                                  compile=False)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "decoder.compile(optimizer=optimizer, loss='mse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test and validation data\n",
    "test_loss = decoder.evaluate(x_test, y_test)\n",
    "print(f'Test loss: {test_loss:.4e}')\n",
    "\n",
    "# get predictions\n",
    "test_pred = decoder.predict(x_test, verbose=False)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Calculate error per variable\n",
    "# mses = mean_squared_error(y_test, test_pred, multioutput='raw_values')\n",
    "\n",
    "# valid_loss = decoder.evaluate(x_valid, y_valid)\n",
    "# print(f'Valid loss: {valid_loss:.4e}')\n",
    "# valid_pred = decoder.predict(x_valid, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "print(np.max(y_test))\n",
    "print(np.min(y_test))\n",
    "mse_image = np.mean((y_test - test_pred) ** 2, axis=0)\n",
    "mse_image = mse_image.reshape((128, 128))\n",
    "\n",
    "me_image = np.mean(np.abs(y_test - test_pred), axis=0)\n",
    "me_image = me_image.reshape((128, 128))\n",
    "\n",
    "# Create 3x3 grid of figures\n",
    "fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(10, 8))\n",
    "\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "# show the image\n",
    "plt.imshow(me_image, cmap='jet', aspect='auto')\n",
    "plt.colorbar()\n",
    "# Set the label\n",
    "# title = ','.join([f'{num:.1f}' for num in samples_X[i]])\n",
    "ax.set_title(f'Mean Diff.')\n",
    "\n",
    "# for i in range(len(axes)):\n",
    "#     ax = axes[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# plot some of the outputs\n",
    "\n",
    "nrows = 5\n",
    "# Get nrows * nrows random images\n",
    "sample = np.random.choice(np.arange(len(y_test)),\n",
    "                          size=nrows, replace=False)\n",
    "\n",
    "samples_real = y_test[sample]\n",
    "samples_pred = test_pred[sample]\n",
    "\n",
    "# Create 3x3 grid of figures\n",
    "fig, axes = plt.subplots(ncols=3, nrows=nrows, figsize=(12, 20))\n",
    "# axes = np.ravel(axes)\n",
    "for i in range(nrows):\n",
    "    ax = axes[i][0]\n",
    "    plt.sca(ax)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    # show the image\n",
    "    ax.imshow(samples_real[i]+1, cmap='jet', vmin=0, vmax=2)\n",
    "    # Set the label\n",
    "    # title = ','.join([f'{num:.1f}' for num in samples_X[i]])\n",
    "    ax.set_title(f'True')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    ax = axes[i][1]\n",
    "    plt.sca(ax)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    # show the image\n",
    "    ax.imshow(samples_pred[i]+1, cmap='jet', vmin=0, vmax=2)\n",
    "    # Set the label\n",
    "    # title = ','.join([f'{num:.1f}' for num in samples_X[i]])\n",
    "    ax.set_title(f'Predicted')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    ax = axes[i][2]\n",
    "    plt.sca(ax)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    # show the image\n",
    "    plt.imshow(np.abs(samples_real[i] -\n",
    "              samples_pred[i]), cmap='jet', vmin=0, vmax=2,\n",
    "              aspect='auto')\n",
    "    plt.colorbar()\n",
    "    # Set the label\n",
    "    # title = ','.join([f'{num:.1f}' for num in samples_X[i]])\n",
    "    ax.set_title(f'Diff')\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 13:09:58) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "79ab8fd01a8cec42884b8b2a5d7fb4751c5402d97e9e61d151ed5c6a6352873c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
