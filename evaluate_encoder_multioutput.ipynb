{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-26 17:31:26.597049: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-26 17:31:26.733677: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-10-26 17:31:26.737198: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/kiliakis/install/lib:/usr/lib/x86_64-linux-gnu\n",
      "2022-10-26 17:31:26.737206: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-10-26 17:31:26.757384: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-26 17:31:27.490663: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/kiliakis/install/lib:/usr/lib/x86_64-linux-gnu\n",
      "2022-10-26 17:31:27.490706: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/kiliakis/install/lib:/usr/lib/x86_64-linux-gnu\n",
      "2022-10-26 17:31:27.490710: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the ML model\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from utils import plot_loss, encoder_files_to_tensors, get_best_model_timestamp\n",
    "from utils import load_model_data_new, unnormalize_params, assess_decoder\n",
    "from utils import sample_files\n",
    "from models import EncoderMulti, mse_loss_encoder, mse_loss_decoder\n",
    "\n",
    "data_dir = '/eos/user/k/kiliakis/tomo_data/datasets'\n",
    "dataset_percent = 0.5\n",
    "normalization = 'minmax'\n",
    "num_Turns_Case = 50+1\n",
    "\n",
    "var_names = ['phEr', 'enEr', 'bl',\n",
    "             'inten', 'Vrf', 'mu', 'VrfSPS']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-26 17:31:38.773344: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/kiliakis/install/lib:/usr/lib/x86_64-linux-gnu\n",
      "2022-10-26 17:31:38.773362: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-10-26 17:31:38.773406: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (sy153): /proc/driver/nvidia/version does not exist\n",
      "2022-10-26 17:31:38.773620: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 42.648, Per file: 0.062\n"
     ]
    }
   ],
   "source": [
    "# Initialize parameters\n",
    "import time\n",
    "\n",
    "# Initialize train/ test / validation paths\n",
    "ML_dir = os.path.join(data_dir, 'ML_data')\n",
    "TESTING_PATH = os.path.join(ML_dir, 'TESTING')\n",
    "assert os.path.exists(TESTING_PATH)\n",
    "\n",
    "\n",
    "# First the training data\n",
    "file_names = sample_files(TESTING_PATH, dataset_percent, keep_every=num_Turns_Case)\n",
    "\n",
    "start_t = time.time()\n",
    "# read input, divide in features/ label, create tensors\n",
    "x_test, y_test = encoder_files_to_tensors(file_names, normalization=normalization)\n",
    "total_time = time.time() - start_t\n",
    "print(f'Elapsed time: {total_time:.3f}, Per file: {total_time/len(file_names):.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022_10_26_15-29-45\n"
     ]
    }
   ],
   "source": [
    "# Model to load\n",
    "# timestamp = get_best_model_timestamp('./trials', model='enc')\n",
    "# timestamp = '2022_10_07_15-18-55'\n",
    "# timestamp = '2022_09_30_17-46-45'\n",
    "# timestamp = '2022_10_24_12-28-57'\n",
    "timestamp = '2022_10_26_15-29-45'\n",
    "\n",
    "print(timestamp)\n",
    "\n",
    "# Initialize directories\n",
    "trial_dir = os.path.join('./trials/', timestamp)\n",
    "weights_dir = os.path.join(trial_dir, 'weights')\n",
    "plots_dir = os.path.join(trial_dir, 'plots')\n",
    "assert os.path.exists(weights_dir)\n",
    "os.makedirs(plots_dir, exist_ok=True)\n",
    "\n",
    "models = {}\n",
    "# load the model\n",
    "for file in os.listdir(weights_dir):\n",
    "    var_name = file.split('encoder_')[1].split('.h5')[0]\n",
    "    models[var_name] = keras.models.load_model(os.path.join(weights_dir, file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Evaluating phEr ------\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1.3309e-04\n",
      "------ Evaluating enEr ------\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 3.6850e-04\n",
      "------ Evaluating bl ------\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 8.8329e-04\n",
      "------ Evaluating inten ------\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0851\n",
      "------ Evaluating Vrf ------\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2.6305e-04\n",
      "------ Evaluating mu ------\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0047\n",
      "------ Evaluating VrfSPS ------\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0029\n",
      "phEr:\t0.0001\n",
      "enEr:\t0.0004\n",
      "bl:\t0.0009\n",
      "inten:\t0.0851\n",
      "Vrf:\t0.0003\n",
      "mu:\t0.0047\n",
      "VrfSPS:\t0.0029\n",
      "\n",
      "Mean loss: 0.0135\n"
     ]
    }
   ],
   "source": [
    "test_losses = {}\n",
    "for var_name, model in models.items():\n",
    "    idx = var_names.index(var_name)\n",
    "    print(f'------ Evaluating {var_name} ------')\n",
    "    test_loss = model.evaluate(x_test, tf.gather(y_test, idx, axis=1))\n",
    "    test_losses[var_name] = test_loss\n",
    "\n",
    "for name, mse in test_losses.items():\n",
    "    print(f'{name}:\\t{mse:.4f}')\n",
    "\n",
    "print(f'\\nMean loss: {np.mean([v for v in test_losses.values()]):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = np.zeros(shape=(len(x_test), len(models)), dtype=float)\n",
    "for var_name, model in models.items():\n",
    "    idx = var_names.index(var_name)\n",
    "    print(f'------ Generating predictions for {var_name} ------')\n",
    "    test_pred[:, idx] = model.predict(x_test, verbose=False).reshape(-1)\n",
    "\n",
    "mses = mean_squared_error(y_test, test_pred, multioutput='raw_values')\n",
    "\n",
    "for name, mse in zip(var_names, mses):\n",
    "    print(f'{name}:\\t{mse:.4f}')\n",
    "\n",
    "print(f'\\nMean loss: {np.mean(mses):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also generate MSE histogram\n",
    "# print(valid_pred.shape)\n",
    "square_errors = ((y_test - test_pred) * (y_test - test_pred))\n",
    "\n",
    "fig, axes = plt.subplots(ncols=1, nrows=len(var_names), sharex=False, \n",
    "sharey=True, figsize=(8, 16))\n",
    "for i, name in enumerate(var_names):\n",
    "    hist,edges = np.histogram(square_errors[:, i], bins=10, density=False)\n",
    "    hist = hist / len(square_errors[:, i])\n",
    "    print(name, hist)\n",
    "    ax = axes[i]\n",
    "    plt.sca(ax)\n",
    "    plt.bar(np.arange(len(hist)), hist, width=0.8)\n",
    "    plt.title(name)\n",
    "    edges = [f'{e:.4f}' for e in edges]\n",
    "    plt.xticks(np.arange(len(hist)), edges[1:])\n",
    "    plt.xlabel('Error')\n",
    "    plt.ylabel('Density')\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_test_unnorm = unnormalize_params(\n",
    "    y_test[:, 0], y_test[:, 1], y_test[:, 2],\n",
    "    y_test[:, 3], y_test[:, 4], y_test[:, 5],\n",
    "    y_test[:, 6], normalization=normalization)\n",
    "\n",
    "y_pred_unnorm = unnormalize_params(\n",
    "    test_pred[:, 0], test_pred[:, 1], test_pred[:, 2],\n",
    "    test_pred[:, 3], test_pred[:, 4], test_pred[:, 5],\n",
    "    test_pred[:, 6], normalization=normalization)\n",
    "\n",
    "diffs = np.array(y_pred_unnorm).T - np.array(y_test_unnorm).T\n",
    "print(diffs.shape)\n",
    "fig, axes = plt.subplots(ncols=1, nrows=len(var_names), sharex=False,\n",
    "                         sharey=True, figsize=(8, 16))\n",
    "fig.suptitle(f'Model id: {timestamp}')\n",
    "\n",
    "plt.sca(axes[0])\n",
    "plt.hist(diffs[:, 0], bins=100, range=(-50, 50))\n",
    "plt.xlabel('Phase Error Diff [deg]')\n",
    "plt.sca(axes[1])\n",
    "plt.hist(diffs[:, 1], bins=100, range=(-100, 100))\n",
    "plt.xlabel('Energy Error Diff [MeV]')\n",
    "plt.sca(axes[2])\n",
    "plt.hist(diffs[:, 2]*1e12, bins=100, range=(-500, 500))\n",
    "plt.xlabel('Bunch length Diff [ps]')\n",
    "plt.sca(axes[3])\n",
    "plt.hist(diffs[:, 3]*1e-10, bins=100, range=(-10.5, 10.5))\n",
    "plt.xlabel('Intensity diff [1e9 prot]')\n",
    "plt.sca(axes[4])\n",
    "plt.hist(diffs[:, 4], bins=100, range=(-0.3, 0.3))\n",
    "plt.xlabel('V_rf diff [MV]')\n",
    "plt.sca(axes[5])\n",
    "plt.hist(diffs[:, 5], bins=100, range=(-0.5, 0.5))\n",
    "plt.xlabel('mu diff [a.u.]')\n",
    "plt.sca(axes[6])\n",
    "plt.hist(diffs[:, 6], bins=100, range=(-2, 2))\n",
    "plt.xlabel('V_rf SPS diff [MV]')\n",
    "plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "79ab8fd01a8cec42884b8b2a5d7fb4751c5402d97e9e61d151ed5c6a6352873c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
