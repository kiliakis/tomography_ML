{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the input data\n",
    "\n",
    "# from utils import plot_loss, encoder_files_to_tensors, normalize_params\n",
    "# from utils import sample_files\n",
    "from utils import normalizeIMG, real_files_to_tensors\n",
    "\n",
    "import time\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "import yaml\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "# data_dir = '/eos/kiliakis/tomo_data/datasets'\n",
    "# data_dir = './tomo_data/datasets'\n",
    "data_dir = './tomo_data/REAL_DATA_Run2'\n",
    "\n",
    "# Data specific\n",
    "IMG_OUTPUT_SIZE = 128\n",
    "latent_dim = 7  # 6 + the new VrfSPS\n",
    "zeropad = 14\n",
    "start_turn = 1\n",
    "skipturns = 3\n",
    "Ib = 1.16e11\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf_arr = real_files_to_tensors(data_dir)\n",
    "print(wf_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# plot some of the outputs\n",
    "\n",
    "nrows = 2\n",
    "# Get nrows * nrows random images\n",
    "sample = np.random.choice(np.arange(len(wf_arr)),\n",
    "                          size=nrows * nrows, replace=False)\n",
    "\n",
    "samples_X = tf.gather(wf_arr, sample)\n",
    "# samples_X = wf_arr\n",
    "# samples_y = tf.gather(y_train, sample)\n",
    "\n",
    "# Create 3x3 grid of figures\n",
    "fig, axes = plt.subplots(ncols=nrows, nrows=nrows, figsize=(12, 12))\n",
    "axes = np.ravel(axes)\n",
    "for i in range(len(axes)):\n",
    "    ax = axes[i]\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    # show the image\n",
    "    ax.imshow(samples_X[i], cmap='jet')\n",
    "    # Set the label\n",
    "    # title = ','.join([f'{num:.1f}' for num in sample[i]])\n",
    "    ax.set_title(f'{sample[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = os.path.join(data_dir, 'PROFILE_B2_b30660_20180908022914.npy')\n",
    "\n",
    "with open(fname, 'rb') as f:\n",
    "    timeScale_for_tomo = np.load(f)\n",
    "    BunchProfiles = np.load(f)\n",
    "\n",
    "origProfiles = BunchProfiles.copy()\n",
    "\n",
    "fig, ax_arr = plt.subplots(ncols=3)\n",
    "plt.sca(ax_arr[0])\n",
    "plt.plot(timeScale_for_tomo)\n",
    "\n",
    "plt.sca(ax_arr[1])\n",
    "plt.plot(origProfiles[:, 0])\n",
    "\n",
    "# plt.show()\n",
    "# print(timeScale_for_tomo.shape)\n",
    "# print(BunchProfiles.shape)\n",
    "\n",
    "BunchProfiles = BunchProfiles*Ib/np.sum(BunchProfiles[:, 0])\n",
    "plt.sca(ax_arr[2])\n",
    "plt.plot(BunchProfiles[:, 0])\n",
    "\n",
    "# print(BunchProfiles.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTimgForModelFromDataFile(BunchProfiles, T_normFactor, IMG_OUTPUT_SIZE, zeropad, start_turn, skipturns, centroid_offset=0):\n",
    "    # timeScale_for_tomo, BunchProfiles = getTimeProfiles_FromData(fname, Ib)\n",
    "    BunchProfiles = BunchProfiles/T_normFactor\n",
    "    sel_turns = np.arange(start_turn, skipturns *\n",
    "                          (IMG_OUTPUT_SIZE-2*zeropad), skipturns).astype(np.int32)\n",
    "    T_img = np.pad(BunchProfiles[:, sel_turns], ((zeropad-centroid_offset, zeropad +\n",
    "                                                  centroid_offset), (zeropad, zeropad)), 'constant', constant_values=(0, 0))\n",
    "    # T_img_ForModel = normalizeIMG(np.reshape(T_img, T_img.shape+(1,)))\n",
    "    T_img_ForModel = np.reshape(T_img, T_img.shape+(1,))\n",
    "    return T_img_ForModel\n",
    "\n",
    "origTimg = getTimgForModelFromDataFile(origProfiles, 1, IMG_OUTPUT_SIZE, zeropad, start_turn, skipturns)\n",
    "adjustedTimg = getTimgForModelFromDataFile(BunchProfiles, 1, IMG_OUTPUT_SIZE, zeropad, start_turn, skipturns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(origTimg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, nrows=2, figsize=(10, 10))\n",
    "axes = np.ravel(axes)\n",
    "ax = axes[0]\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "# show the image\n",
    "ax.imshow(origTimg, cmap='jet')\n",
    "print(np.min(origTimg), np.max(origTimg))\n",
    "# Set the label\n",
    "title = 'Orig'\n",
    "ax.set_title(f'{title}')\n",
    "\n",
    "ax = axes[1]\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "# show the image\n",
    "ax.imshow(adjustedTimg, cmap='jet')\n",
    "print(np.min(adjustedTimg), np.max(adjustedTimg))\n",
    "\n",
    "# Set the label\n",
    "title = 'Adjusted'\n",
    "ax.set_title(f'{title}')\n",
    "\n",
    "# from sklearn.preprocessing import minmax_scale\n",
    "def minmax_scale(X, feature_range=(0,1)):\n",
    "    min_val = np.min(X)\n",
    "    max_val = np.max(X)\n",
    "    scale = (feature_range[1] - feature_range[0]) / (max_val - min_val)\n",
    "    return scale * (X-min_val) + feature_range[0]\n",
    "\n",
    "ax = axes[2]\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "# show the image\n",
    "origTimg_scaled = minmax_scale(origTimg.reshape(IMG_OUTPUT_SIZE, IMG_OUTPUT_SIZE))\n",
    "ax.imshow(origTimg_scaled, cmap='jet')\n",
    "print(np.min(origTimg_scaled), np.max(origTimg_scaled))\n",
    "# Set the label\n",
    "title = 'Orig_scaled'\n",
    "ax.set_title(f'{title}')\n",
    "\n",
    "ax = axes[3]\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "# show the image\n",
    "adjustedTimg_scaled = minmax_scale(adjustedTimg.reshape(IMG_OUTPUT_SIZE, IMG_OUTPUT_SIZE))\n",
    "ax.imshow(adjustedTimg_scaled, cmap='jet')\n",
    "print(np.min(adjustedTimg_scaled), np.max(adjustedTimg_scaled))\n",
    "\n",
    "# Set the label\n",
    "title = 'Adjusted_scaled'\n",
    "ax.set_title(f'{title}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "79ab8fd01a8cec42884b8b2a5d7fb4751c5402d97e9e61d151ed5c6a6352873c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
