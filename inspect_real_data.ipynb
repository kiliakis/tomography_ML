{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed to reload modified modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the input data\n",
    "\n",
    "# from utils import plot_loss, encoder_files_to_tensors, normalize_params\n",
    "# from utils import sample_files\n",
    "from utils import normalizeIMG, real_files_to_tensors\n",
    "from utils import normalizeTurn\n",
    "import time\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import yaml\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "# some initializations\n",
    "data_dir = './tomo_data/REAL_DATA_Run2'\n",
    "\n",
    "IMG_OUTPUT_SIZE = 128\n",
    "latent_dim = 7  # 6 + the new VrfSPS\n",
    "\n",
    "zeropad = 14\n",
    "start_turn = 1\n",
    "skipturns = 3\n",
    "Ib = 1.16e11\n",
    "\n",
    "normalization = 'minmax'\n",
    "var_names = ['phEr', 'enEr', 'bl',\n",
    "             'inten', 'Vrf', 'mu',\n",
    "             'VrfSPS']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf_test, wf_id = real_files_to_tensors(data_dir)\n",
    "print(wf_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# plot some of the outputs\n",
    "\n",
    "nrows = 2\n",
    "# Get nrows * nrows random images\n",
    "sample = np.random.choice(np.arange(len(wf_test)),\n",
    "                          size=nrows * nrows, replace=False)\n",
    "\n",
    "samples_X = tf.gather(wf_test, sample)\n",
    "\n",
    "# Create 3x3 grid of figures\n",
    "fig, axes = plt.subplots(ncols=nrows, nrows=nrows, figsize=(12, 12))\n",
    "axes = np.ravel(axes)\n",
    "for i in range(len(axes)):\n",
    "    ax = axes[i]\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    # show the image\n",
    "    ax.imshow(samples_X[i], cmap='jet')\n",
    "    # Set the label\n",
    "    # title = ','.join([f'{num:.1f}' for num in sample[i]])\n",
    "    ax.set_title(f'{sample[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing the models on the real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the turns\n",
    "# select 30 turns\n",
    "selected_turns = np.linspace(1, 300, 30, endpoint=True, dtype=float)\n",
    "selected_turns = normalizeTurn(selected_turns)\n",
    "\n",
    "# get the predictions\n",
    "# latent_pred, ps_pred = encDec.predictPS(wf_test, turn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the predictions\n",
    "for turn in selected_turns:\n",
    "    # expand turns to be equal to the number of test points\n",
    "    turn_test = np.ones(len(wf_test), dtype=float)*turn\n",
    "    # get the predictions\n",
    "    latent_pred, ps_pred = encDec.predictPS(wf_test, turn_test)\n",
    "    # Now I need to plot them\n",
    "    # one directory per WF\n",
    "    for i in range(len(wf_test)):\n",
    "        # save in a figure the turn, latents, input image, output image\n",
    "        os.makedirs(f'plots/real_data/{wf_id[i]}', exist_ok=True)\n",
    "        fig, axes = plt.subplots(ncols=3, figsize=(10, 5))\n",
    "# ax[0] the input\n",
    "# ax[1] the latents \n",
    "# ax[2] the PS, turn\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the encoder and decoder models\n",
    "# enc_timestamp = get_best_model_timestamp('./trials', model='enc')\n",
    "enc_timestamp = 'hybrid'\n",
    "\n",
    "print('Encoder: ', enc_timestamp)\n",
    "\n",
    "# Initialize directories\n",
    "enc_trial_dir = os.path.join('./trials/', enc_timestamp)\n",
    "enc_weights_dir = os.path.join(enc_trial_dir, 'weights')\n",
    "assert os.path.exists(enc_weights_dir)\n",
    "\n",
    "dec_timestamp = '2022_12_14_22-03-08'\n",
    "print('Decoder: ', dec_timestamp)\n",
    "\n",
    "# Initialize directories\n",
    "dec_trial_dir = os.path.join('./trials/', dec_timestamp)\n",
    "dec_weights_dir = os.path.join(dec_trial_dir, 'weights')\n",
    "assert os.path.exists(dec_weights_dir)\n",
    "\n",
    "# initialize directory to save the plots\n",
    "timestamp = f'enc_{enc_timestamp}_dec_{dec_timestamp}'\n",
    "print('Timestamp: ', timestamp)\n",
    "plots_dir = os.path.join('./plots', 'end_to_end', timestamp)\n",
    "os.makedirs(plots_dir, exist_ok=True)\n",
    "\n",
    "encDec = encoderDecoderModel(enc_weights_dir, dec_weights_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = os.path.join(data_dir, 'PROFILE_B2_b30660_20180908022914.npy')\n",
    "\n",
    "with open(fname, 'rb') as f:\n",
    "    timeScale_for_tomo = np.load(f)\n",
    "    BunchProfiles = np.load(f)\n",
    "\n",
    "origProfiles = BunchProfiles.copy()\n",
    "\n",
    "fig, ax_arr = plt.subplots(ncols=3)\n",
    "plt.sca(ax_arr[0])\n",
    "plt.plot(timeScale_for_tomo)\n",
    "\n",
    "plt.sca(ax_arr[1])\n",
    "plt.plot(origProfiles[:, 0])\n",
    "\n",
    "# plt.show()\n",
    "# print(timeScale_for_tomo.shape)\n",
    "# print(BunchProfiles.shape)\n",
    "\n",
    "BunchProfiles = BunchProfiles*Ib/np.sum(BunchProfiles[:, 0])\n",
    "plt.sca(ax_arr[2])\n",
    "plt.plot(BunchProfiles[:, 0])\n",
    "\n",
    "# print(BunchProfiles.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTimgForModelFromDataFile(BunchProfiles, T_normFactor, IMG_OUTPUT_SIZE, zeropad, start_turn, skipturns, centroid_offset=0):\n",
    "    # timeScale_for_tomo, BunchProfiles = getTimeProfiles_FromData(fname, Ib)\n",
    "    BunchProfiles = BunchProfiles/T_normFactor\n",
    "    sel_turns = np.arange(start_turn, skipturns *\n",
    "                          (IMG_OUTPUT_SIZE-2*zeropad), skipturns).astype(np.int32)\n",
    "    T_img = np.pad(BunchProfiles[:, sel_turns], ((zeropad-centroid_offset, zeropad +\n",
    "                                                  centroid_offset), (zeropad, zeropad)), 'constant', constant_values=(0, 0))\n",
    "    # T_img_ForModel = normalizeIMG(np.reshape(T_img, T_img.shape+(1,)))\n",
    "    T_img_ForModel = np.reshape(T_img, T_img.shape+(1,))\n",
    "    return T_img_ForModel\n",
    "\n",
    "origTimg = getTimgForModelFromDataFile(origProfiles, 1, IMG_OUTPUT_SIZE, zeropad, start_turn, skipturns)\n",
    "adjustedTimg = getTimgForModelFromDataFile(BunchProfiles, 1, IMG_OUTPUT_SIZE, zeropad, start_turn, skipturns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(origTimg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, nrows=2, figsize=(10, 10))\n",
    "axes = np.ravel(axes)\n",
    "ax = axes[0]\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "# show the image\n",
    "ax.imshow(origTimg, cmap='jet')\n",
    "print(np.min(origTimg), np.max(origTimg))\n",
    "# Set the label\n",
    "title = 'Orig'\n",
    "ax.set_title(f'{title}')\n",
    "\n",
    "ax = axes[1]\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "# show the image\n",
    "ax.imshow(adjustedTimg, cmap='jet')\n",
    "print(np.min(adjustedTimg), np.max(adjustedTimg))\n",
    "\n",
    "# Set the label\n",
    "title = 'Adjusted'\n",
    "ax.set_title(f'{title}')\n",
    "\n",
    "# from sklearn.preprocessing import minmax_scale\n",
    "def minmax_scale(X, feature_range=(0,1)):\n",
    "    min_val = np.min(X)\n",
    "    max_val = np.max(X)\n",
    "    scale = (feature_range[1] - feature_range[0]) / (max_val - min_val)\n",
    "    return scale * (X-min_val) + feature_range[0]\n",
    "\n",
    "ax = axes[2]\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "# show the image\n",
    "origTimg_scaled = minmax_scale(origTimg.reshape(IMG_OUTPUT_SIZE, IMG_OUTPUT_SIZE))\n",
    "ax.imshow(origTimg_scaled, cmap='jet')\n",
    "print(np.min(origTimg_scaled), np.max(origTimg_scaled))\n",
    "# Set the label\n",
    "title = 'Orig_scaled'\n",
    "ax.set_title(f'{title}')\n",
    "\n",
    "ax = axes[3]\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "# show the image\n",
    "adjustedTimg_scaled = minmax_scale(adjustedTimg.reshape(IMG_OUTPUT_SIZE, IMG_OUTPUT_SIZE))\n",
    "ax.imshow(adjustedTimg_scaled, cmap='jet')\n",
    "print(np.min(adjustedTimg_scaled), np.max(adjustedTimg_scaled))\n",
    "\n",
    "# Set the label\n",
    "title = 'Adjusted_scaled'\n",
    "ax.set_title(f'{title}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "79ab8fd01a8cec42884b8b2a5d7fb4751c5402d97e9e61d151ed5c6a6352873c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
