{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed to reload modified modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Encoder-Decoder models\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from utils import sample_files, encdec_files_to_tensors\n",
    "from utils import get_best_model_timestamp\n",
    "from utils import unnormalize_params, unnormalizeTurn\n",
    "from models import encoderDecoderModel\n",
    "\n",
    "# data_dir = '/eos/user/k/kiliakis/tomo_data/datasets_decoder_02-12-22'\n",
    "data_dir = './tomo_data/datasets_decoder_02-12-22'\n",
    "dataset_percent = 0.01\n",
    "normalization = 'minmax'\n",
    "var_names = ['phEr', 'enEr', 'bl',\n",
    "             'inten', 'Vrf', 'mu',\n",
    "             'VrfSPS']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "import time\n",
    "\n",
    "# Initialize train/ test / validation paths\n",
    "ML_dir = os.path.join(data_dir, 'ML_data')\n",
    "TESTING_PATH = os.path.join(ML_dir, 'TESTING')\n",
    "assert os.path.exists(TESTING_PATH)\n",
    "\n",
    "\n",
    "# First the training data\n",
    "file_names = sample_files(TESTING_PATH, dataset_percent)\n",
    "\n",
    "start_t = time.time()\n",
    "# read input, divide in features/ label, create tensors\n",
    "wf_test, turn_test, latent_test, ps_test = encdec_files_to_tensors(\n",
    "    file_names, normalization=normalization)\n",
    "total_time = time.time() - start_t\n",
    "print(f'Elapsed time: {total_time:.3f}, Per file: {total_time/len(file_names):.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models to load\n",
    "# enc_timestamp = get_best_model_timestamp('./trials', model='enc')\n",
    "enc_timestamp = 'hybrid'\n",
    "\n",
    "print('Encoder: ', enc_timestamp)\n",
    "\n",
    "# Initialize directories\n",
    "enc_trial_dir = os.path.join('./trials/', enc_timestamp)\n",
    "enc_weights_dir = os.path.join(enc_trial_dir, 'weights')\n",
    "assert os.path.exists(enc_weights_dir)\n",
    "\n",
    "dec_timestamp = '2022_12_14_22-03-08'\n",
    "print('Decoder: ', dec_timestamp)\n",
    "\n",
    "# Initialize directories\n",
    "dec_trial_dir = os.path.join('./trials/', dec_timestamp)\n",
    "dec_weights_dir = os.path.join(dec_trial_dir, 'weights')\n",
    "assert os.path.exists(dec_weights_dir)\n",
    "\n",
    "# initialize directory to save the plots\n",
    "timestamp = f'enc_{enc_timestamp}_dec_{dec_timestamp}'\n",
    "print('Timestamp: ', timestamp)\n",
    "plots_dir = os.path.join('./plots', 'end_to_end', timestamp)\n",
    "os.makedirs(plots_dir, exist_ok=True)\n",
    "\n",
    "encDec = encoderDecoderModel(enc_weights_dir, dec_weights_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate the model on the test and validation data\n",
    "latent_pred, ps_pred = encDec.predictPS(wf_test, turn_test)\n",
    "\n",
    "# Evaluate the latent space agreemet \n",
    "latent_mse = mean_squared_error(latent_test, latent_pred, multioutput='raw_values') \n",
    "print('Variable\\tMSE')\n",
    "for name, mse in zip(var_names, latent_mse):\n",
    "    print(f'{name}:\\t{mse:.3e}')\n",
    "\n",
    "# Evaluate the PS agreement\n",
    "ps_enc_dec_mse = np.mean((ps_test - ps_pred)**2, axis=0).reshape((128, 128))\n",
    "print('\\nPS Encoder-Decoder MSE: ', np.mean(ps_enc_dec_mse))\n",
    "\n",
    "# Evaluate the PS agreement with perfect encoder\n",
    "ps_dec_pred = encDec.decode(latent_test, turn_test)\n",
    "ps_dec_mse = np.mean((ps_test - ps_dec_pred)**2, axis=0).reshape((128, 128))\n",
    "print('\\nPS Decoder MSE: ', np.mean(ps_dec_mse))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder, graphical evaluation\n",
    "\n",
    "# unormalized latent space\n",
    "latent_unnorm = unnormalize_params(\n",
    "    latent_test[:, 0], latent_test[:, 1], latent_test[:, 2],\n",
    "    latent_test[:, 3], latent_test[:, 4], latent_test[:, 5],\n",
    "    latent_test[:, 6], normalization=normalization)\n",
    "latent_unnorm = np.array(latent_unnorm).T\n",
    "\n",
    "# unormalized predicted latent space\n",
    "latent_pred_unnorm = unnormalize_params(\n",
    "    latent_pred[:, 0], latent_pred[:, 1], latent_pred[:, 2],\n",
    "    latent_pred[:, 3], latent_pred[:, 4], latent_pred[:, 5],\n",
    "    latent_pred[:, 6], normalization=normalization)\n",
    "latent_pred_unnorm = np.array(latent_pred_unnorm).T\n",
    "\n",
    "# absolute difference\n",
    "diffs = np.abs(latent_unnorm - latent_pred_unnorm)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, nrows=3, sharex=False,\n",
    "                         sharey=False, figsize=(8, 6))\n",
    "\n",
    "plt.sca(axes[0][0])\n",
    "plt.hist(diffs[:, 0], bins=10, range=(0, 10))\n",
    "plt.xticks(np.arange(0, 10.5))\n",
    "plt.xlabel('Phase Error [deg]')\n",
    "plt.ylabel('No. Samples')\n",
    "plt.axvline(x=2, color='tab:red')\n",
    "\n",
    "plt.sca(axes[1][0])\n",
    "plt.hist(diffs[:, 1], bins=10, range=(0, 10))\n",
    "plt.xticks(np.arange(0, 10.5))\n",
    "plt.xlabel('Energy Error [MeV]')\n",
    "plt.ylabel('No. Samples')\n",
    "plt.axvline(x=2, color='tab:red')\n",
    "\n",
    "plt.sca(axes[2][0])\n",
    "plt.hist(diffs[:, 2]*1e12, bins=50, range=(0, 50))\n",
    "plt.xticks(np.arange(0, 50.5, 5))\n",
    "plt.xlabel('Bunch Length [ps]')\n",
    "plt.ylabel('No. Samples')\n",
    "plt.axvline(x=25, color='tab:red')\n",
    "\n",
    "plt.sca(axes[0][1])\n",
    "plt.hist(diffs[:, 4], bins=50, range=(0, 0.3))\n",
    "plt.xlabel('V_rf [MV]')\n",
    "plt.axvline(x=0.1, color='tab:red')\n",
    "\n",
    "plt.sca(axes[1][1])\n",
    "plt.hist(diffs[:, 5], bins=50, range=(0, 0.7))\n",
    "plt.xticks(np.arange(0, 0.71, 0.1))\n",
    "plt.xlabel('mu [a.u.]')\n",
    "plt.axvline(x=0.2, color='tab:red')\n",
    "\n",
    "plt.sca(axes[2][1])\n",
    "plt.hist(diffs[:, 6], bins=50, range=(0, 1))\n",
    "plt.xticks(np.arange(0, 1.1, 0.25))\n",
    "plt.xlabel('V_rf SPS [MV]')\n",
    "plt.axvline(x=0.1, color='tab:red')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(plots_dir, 'encoder_absError.jpg'), dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "\n",
    "'''\n",
    "These plots are used for the evaluation of the encoder part. \n",
    "They show the cumulative distribution of absolute error. \n",
    "The black vertical line corresponds to the required prediction, i.e. ideally all\n",
    "predictions would have less error than the required. \n",
    "The vertical orange line shows the 95th percentile, i.e. 95% of the test points \n",
    "have error less than this value.\n",
    "If the orange line is to the left of the black line, it means that more than 95%\n",
    "of the test points have less error than the required value.   \n",
    "'''\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, nrows=3, sharex=False,\n",
    "                         sharey=False, figsize=(8, 6))\n",
    "\n",
    "plt.sca(axes[0][0])\n",
    "n, bins, patches = plt.hist(diffs[:, 0], bins=50, range=(0, 10),\n",
    "                            cumulative=True, density=True, label='CumHist')\n",
    "b = bisect.bisect(n, 0.95)\n",
    "plt.axvline(x=bins[b+1], color='tab:orange', label='95% max error')\n",
    "plt.xticks(np.arange(0, 10.5))\n",
    "plt.xlabel('Phase Error [deg]')\n",
    "plt.ylabel('No. Samples')\n",
    "plt.axvline(x=2, color='black', label='Desired')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.sca(axes[1][0])\n",
    "n, bins, patches = plt.hist(diffs[:, 1], bins=50, range=(0, 10),\n",
    "                            cumulative=True, density=True, label='CumHist')\n",
    "b = bisect.bisect(n, 0.95)\n",
    "plt.axvline(x=bins[b+1], color='tab:orange', label='95% max error')\n",
    "plt.xticks(np.arange(0, 10.5))\n",
    "plt.xlabel('Energy Error [MeV]')\n",
    "plt.ylabel('No. Samples')\n",
    "plt.axvline(x=2, color='black', label='Desired')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.sca(axes[2][0])\n",
    "n, bins, patches = plt.hist(\n",
    "    diffs[:, 2]*1e12, bins=50, range=(0, 50),\n",
    "    cumulative=True, density=True, label='CumHist')\n",
    "b = bisect.bisect(n, 0.95)\n",
    "plt.axvline(x=bins[b+1], color='tab:orange', label='95% max error')\n",
    "plt.xticks(np.arange(0, 50.5, 5))\n",
    "plt.xlabel('Bunch Length [ps]')\n",
    "plt.ylabel('No. Samples')\n",
    "plt.axvline(x=25, color='black', label='Desired')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.sca(axes[0][1])\n",
    "n, bins, patches = plt.hist(diffs[:, 4], bins=50, range=(0, 0.3),\n",
    "                            cumulative=True, density=True, label='CumHist')\n",
    "b = bisect.bisect(n, 0.95)\n",
    "plt.axvline(x=bins[b+1], color='tab:orange', label='95% max error')\n",
    "plt.xlabel('V_rf [MV]')\n",
    "plt.axvline(x=0.1, color='black', label='Desired')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.sca(axes[1][1])\n",
    "n, bins, patches = plt.hist(diffs[:, 5], bins=50, range=(0, 0.7),\n",
    "                            cumulative=True, density=True, label='CumHist')\n",
    "b = bisect.bisect(n, 0.95)\n",
    "plt.axvline(x=bins[b+1], color='tab:orange', label='95% max error')\n",
    "plt.xticks(np.arange(0, 0.71, 0.1))\n",
    "plt.xlabel('mu [a.u.]')\n",
    "plt.axvline(x=0.2, color='black', label='Desired')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.sca(axes[2][1])\n",
    "n, bins, patches = plt.hist(diffs[:, 6], bins=50, range=(0, 1),\n",
    "                            cumulative=True, density=True, label='CumHist')\n",
    "b = bisect.bisect(n, 0.95)\n",
    "plt.axvline(x=bins[b+1], color='tab:orange', label='95% max error')\n",
    "plt.xticks(np.arange(0, 1.1, 0.25))\n",
    "plt.xlabel('V_rf SPS [MV]')\n",
    "plt.axvline(x=0.1, color='black', label='Desired')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(plots_dir, 'encoder_cumError.jpg'), dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Visual end-to-end evaluation. \n",
    "Left: Waterfall (input)\n",
    "Middle: Bar plot with features (latent space), real and predicted. For the evaluation of the encoder. \n",
    "Middle bottom: PS at a given turn, real and predicted. For the evaluation of the decoder. \n",
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "fig, axes = plt.subplot_mosaic(mosaic=[['WF', 'TAB', 'PS_TRUE'],\n",
    "                                       ['WF', 'TAB', 'PS_PRED']],\n",
    "                               gridspec_kw={'width_ratios': [3, 3, 2]},\n",
    "                               #        'hspace': 0.1, 'wspace': 0.2},\n",
    "                               figsize=(12, 6))\n",
    "\n",
    "# get random id\n",
    "sample_id = np.random.randint(low=0, high=len(file_names))\n",
    "wf_s = np.array(wf_test[sample_id]).reshape(128, 128).T\n",
    "latent_true_s = latent_unnorm[sample_id]\n",
    "latent_pred_s = latent_pred_unnorm[sample_id]\n",
    "latent_norm_true_s = np.array(latent_test[sample_id])\n",
    "latent_norm_pred_s = np.array(latent_pred[sample_id])\n",
    "\n",
    "turn_s = turn_test[sample_id]\n",
    "turn_s = int(unnormalizeTurn(turn_s, maxTurns=300))\n",
    "ps_true_s = ps_test[sample_id]\n",
    "ps_pred_s = ps_pred[sample_id]\n",
    "\n",
    "# # start with left plot, the waterfall\n",
    "plt.sca(axes['WF'])\n",
    "plt.imshow(wf_s, cmap='jet')\n",
    "plt.title(f'Waterfall ID: {sample_id}', fontsize=14)\n",
    "plt.xticks([], []); plt.yticks([], [])\n",
    "\n",
    "# center plot\n",
    "plt.sca(axes['TAB'])\n",
    "plt.gca().set_facecolor('xkcd:light grey')\n",
    "# Remove inten, since it is very hard to predict\n",
    "latent_true_s = np.delete(latent_true_s, var_names.index('inten'))\n",
    "latent_pred_s = np.delete(latent_pred_s, var_names.index('inten'))\n",
    "latent_norm_true_s = np.delete(latent_norm_true_s, var_names.index('inten'))\n",
    "latent_norm_pred_s = np.delete(latent_norm_pred_s, var_names.index('inten'))\n",
    "\n",
    "reduced_var_names = var_names.copy()\n",
    "reduced_var_names.remove('inten')\n",
    "\n",
    "bars = plt.barh(np.arange(len(latent_true_s)),\n",
    "                height=0.35, width=(latent_norm_true_s),\n",
    "                edgecolor='black', label='True')\n",
    "\n",
    "for idx, width in enumerate(latent_norm_true_s):\n",
    "    plt.annotate(f'{latent_true_s[idx]:.2e}',\n",
    "                 xy=(width, idx),\n",
    "                 ha='left', va='center',\n",
    "                 fontsize=14)\n",
    "\n",
    "plt.barh(np.arange(len(latent_true_s)) + 0.4,\n",
    "         height=0.35, width=latent_norm_pred_s,\n",
    "         edgecolor='black', label='Pred')\n",
    "\n",
    "for idx, width in enumerate(latent_norm_pred_s):\n",
    "    plt.annotate(f'{latent_pred_s[idx]:.2e}',\n",
    "                 xy=(width, idx+0.4),\n",
    "                 ha='left', va='center',\n",
    "                 fontsize=14)\n",
    "plt.xlim(0, 1.3)\n",
    "\n",
    "\n",
    "plt.yticks(np.arange(len(latent_true_s))+0.25, reduced_var_names, fontsize=14)\n",
    "plt.xticks([], [])\n",
    "plt.legend(loc='lower left',fontsize=14, ncols=2)\n",
    "\n",
    "# top right plot\n",
    "plt.sca(axes['PS_TRUE'])\n",
    "print(f'PS True, min: {np.min(ps_true_s)}, max: {np.max(ps_true_s)}')\n",
    "plt.imshow(ps_true_s, cmap='jet', vmin=-1, vmax=1)\n",
    "plt.title(f'True PS, Turn: {turn_s}', fontsize=14)\n",
    "plt.xticks([], []); plt.yticks([], [])\n",
    "\n",
    "# bottom right plot\n",
    "plt.sca(axes['PS_PRED'])\n",
    "print(f'PS Pred, min: {np.min(ps_pred_s)}, max: {np.max(ps_pred_s)}')\n",
    "plt.imshow(ps_pred_s, cmap='jet', vmin=-1, vmax=1)\n",
    "plt.title(f'Pred PS, MSE: {np.mean((ps_pred_s - ps_true_s)**2):.3e}', fontsize=14)\n",
    "plt.xticks([], []); plt.yticks([], [])\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(os.path.join(plots_dir, f'encDec_id{sample_id}_turn{turn_s}.jpg'), dpi=400)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import assess_decoder\n",
    "assess_decoder(ps_pred[:5], turn_test[:5], ps_test[:5],\n",
    "               plots_dir=plots_dir, savefig=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import assess_model\n",
    "assess_model(ps_pred[:5], turn_test[:5], wf_test[:5], ps_test[:5],\n",
    "             plots_dir=plots_dir, savefig=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "79ab8fd01a8cec42884b8b2a5d7fb4751c5402d97e9e61d151ed5c6a6352873c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
