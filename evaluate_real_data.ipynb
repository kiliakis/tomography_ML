{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed to reload modified modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the input data\n",
    "import time\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import yaml\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from utils import normalizeIMG, real_files_to_tensors, window_mean\n",
    "from utils import minmax_normalize_param, unnormalize_params\n",
    "\n",
    "from models import encoderDecoderModel\n",
    "\n",
    "# some initializations\n",
    "# data_dir = './tomo_data/REAL_DATA_Run2'\n",
    "data_dir = './tomo_data/REAL_DATA_Run2_2'\n",
    "\n",
    "IMG_OUTPUT_SIZE = 128\n",
    "latent_dim = 7  # 6 + the new VrfSPS\n",
    "\n",
    "zeropad = 14\n",
    "start_turn = 1\n",
    "skipturns = 3\n",
    "Ib = 1.16e11\n",
    "\n",
    "normalization = 'minmax'\n",
    "img_normalize = 'off'\n",
    "ps_normalize = 'off'\n",
    "\n",
    "E_normFactor = 25000000000.0\n",
    "B_normFactor = 800000000.0\n",
    "T_normFactor = 28000000000.0\n",
    "\n",
    "var_names = ['phEr', 'enEr', 'bl','inten', 'Vrf', 'mu', 'VrfSPS']\n",
    "loss_weights = [0, 1, 2, 3, 4, 5, 6]\n",
    "\n",
    "# enc_timestamp = get_best_model_timestamp('./trials', model='enc')\n",
    "enc_timestamp = 'best_encoder_TF'\n",
    "dec_timestamp = 'best_decoder_TF'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wf_test_orig, wf_id, bunch_profiles_orig = real_files_to_tensors(data_dir,\n",
    "                                                                 Ib=Ib,\n",
    "                                                                 T_normFactor=T_normFactor,\n",
    "                                                                 corrTriggerOffset=False)\n",
    "print(wf_test_orig.shape)\n",
    "print(bunch_profiles_orig.shape)\n",
    "print('Max value in wf: ', np.max(wf_test_orig))\n",
    "print('Min value in wf: ', np.min(wf_test_orig))\n",
    "\n",
    "# Correct the input data\n",
    "wf_test, _, bunch_profiles = real_files_to_tensors(data_dir,\n",
    "                                                   Ib=Ib,\n",
    "                                                   T_normFactor=T_normFactor,\n",
    "                                                   corrTriggerOffset=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# plot some of the outputs\n",
    "\n",
    "nrows = 2\n",
    "# Get nrows * nrows random images\n",
    "sample = np.random.choice(np.arange(len(wf_test_orig)),\n",
    "                          size=nrows, replace=False)\n",
    "\n",
    "samples_X = tf.gather(wf_test_orig, sample)\n",
    "\n",
    "# Create 3x3 grid of figures\n",
    "fig, axes = plt.subplots(ncols=nrows, nrows=nrows, figsize=(12, 12))\n",
    "axes = np.ravel(axes)\n",
    "for i in range(len(sample)):\n",
    "    ax = axes[i]\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    # show the image\n",
    "    ax.imshow(samples_X[i], cmap='jet')\n",
    "    # Set the label\n",
    "    # title = ','.join([f'{num:.1f}' for num in sample[i]])\n",
    "    ax.set_title(f'{wf_id[i]}')\n",
    "\n",
    "    ax = axes[i+2]\n",
    "    # show the image\n",
    "    ax.imshow(bunch_profiles_orig[sample[i]], cmap='jet')\n",
    "    ax.set_title(f'{wf_id[i]}-bunch-profle')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "nrows = 2\n",
    "# Get nrows * nrows random images\n",
    "sample = np.random.choice(np.arange(len(wf_test_orig)),\n",
    "                          size=nrows, replace=False)\n",
    "\n",
    "samples_X = tf.gather(wf_test_orig, sample)\n",
    "samples_X_corrected = tf.gather(wf_test, sample)\n",
    "\n",
    "# Create 3x3 grid of figures\n",
    "fig, axes = plt.subplots(ncols=nrows, nrows=nrows, figsize=(12, 12))\n",
    "axes = np.ravel(axes)\n",
    "# for i in range(len(axes)):\n",
    "for i in range(len(sample)):\n",
    "    ax = axes[i]\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.imshow(samples_X[i], cmap='jet')\n",
    "    ax.set_title(f'{wf_id[i]}')\n",
    "\n",
    "    ax = axes[i+2]\n",
    "    # show the image\n",
    "    ax.imshow(samples_X_corrected[i], cmap='jet')\n",
    "    ax.set_title(f'{wf_id[i]}-corrected')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the models on the real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "print('Encoder: ', enc_timestamp)\n",
    "\n",
    "# Initialize directories\n",
    "enc_trial_dir = os.path.join('./trials/', enc_timestamp)\n",
    "enc_weights_dir = os.path.join(enc_trial_dir, 'weights')\n",
    "assert os.path.exists(enc_weights_dir)\n",
    "\n",
    "print('Decoder: ', dec_timestamp)\n",
    "\n",
    "# Initialize directories\n",
    "dec_trial_dir = os.path.join('./trials/', dec_timestamp)\n",
    "dec_weights_dir = os.path.join(dec_trial_dir, 'weights')\n",
    "assert os.path.exists(dec_weights_dir)\n",
    "\n",
    "# initialize directory to save the plots\n",
    "timestamp = f'enc_{enc_timestamp}_dec_{dec_timestamp}'\n",
    "print('Timestamp: ', timestamp)\n",
    "plots_dir = os.path.join('./plots', 'end_to_end', timestamp)\n",
    "os.makedirs(plots_dir, exist_ok=True)\n",
    "\n",
    "encDec = encoderDecoderModel(enc_weights_dir, dec_weights_dir,\n",
    " loss_weights=loss_weights)\n",
    "\n",
    "# for model in (encDec.encoder.model):\n",
    "#     print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the turns\n",
    "# select a number of turns (31)\n",
    "selected_turns = np.linspace(1, 298, num=28, endpoint=True, dtype=np.float32)\n",
    "print(selected_turns)\n",
    "norm_turns = minmax_normalize_param(selected_turns, np.min(selected_turns),\n",
    "                                    np.max(selected_turns),\n",
    "                                    target_range=(0, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import minMaxScaleIMG\n",
    "def assess_model_real_data(wf, wf_id, bunch_profile, latent_pred, \n",
    "                           ps_pred, turn, figname, savefig=False):\n",
    "    '''\n",
    "    Visual end-to-end evaluation. \n",
    "    Left: Waterfall (input)\n",
    "    Middle: Bar plot with features (latent space), real and predicted. For the evaluation of the encoder. \n",
    "    Middle bottom: PS at a given turn, real and predicted. For the evaluation of the decoder. \n",
    "    '''\n",
    "    fig, axes = plt.subplots(ncols=3, nrows=1, figsize=(12, 5),\n",
    "                            gridspec_kw={'width_ratios': [5, 4, 5]})\n",
    "\n",
    "    wf_s = np.array(wf).reshape(128, 128).T\n",
    "    # wf_s = wf_s[zeropad:-zeropad, zeropad:-zeropad]\n",
    "    latent_pred = latent_pred.numpy().reshape((1, -1))\n",
    "\n",
    "    latent_pred_unnorm = unnormalize_params(\n",
    "        latent_pred[:, 0], latent_pred[:, 1], latent_pred[:, 2],\n",
    "        latent_pred[:, 3], latent_pred[:, 4], latent_pred[:, 5],\n",
    "        latent_pred[:, 6], normalization=normalization)\n",
    "    \n",
    "    # print(latent_pred_unnorm.shape)\n",
    "    # # start with top left plot, the waterfall\n",
    "    plt.sca(axes[0])\n",
    "    plt.imshow(wf_s, cmap='jet')\n",
    "    plt.title(f'{wf_id}', fontsize=12)\n",
    "    # plt.xticks([], []); plt.yticks([], [])\n",
    "\n",
    "    # top right plot\n",
    "    plt.sca(axes[1])\n",
    "    # plt.gca().set_facecolor('xkcd:light grey')\n",
    "    plt.axis('off')\n",
    "    rowLabels = [var_names[w] for w in loss_weights]\n",
    "    # cellText = [[latent] for latent in latent_pred_unnorm]\n",
    "    plt.table(cellText=latent_pred_unnorm, rowLabels=rowLabels,\n",
    "        colLabels=['Value'], loc='center')\n",
    "\n",
    "    # bottome right plot \n",
    "    plt.sca(axes[2])\n",
    "    plt.title(f'Time Projection, Turn: {turn}', fontsize=14)\n",
    "    time_profile_pred = minMaxScaleIMG(np.sum(ps_pred[:, :, 0], 0))\n",
    "\n",
    "    # Which turn? \n",
    "    target_turn = int(minmax_normalize_param(turn, 1, 298, target_range=(zeropad, wf.shape[1] - zeropad-1)))\n",
    "    bunch_profile_turn = int(minmax_normalize_param(turn, 1, 298, target_range=(zeropad, bunch_profile.shape[1]- zeropad-1)))\n",
    "\n",
    "    # wf_turn = zeropad + int((IMG_OUTPUT_SIZE - 2 * zeropad-1) * turn/298)\n",
    "    # print(turn, wf_turn)\n",
    "    time_profile_target = minMaxScaleIMG(wf_s[target_turn, :])\n",
    "    bunch_profile_target = minMaxScaleIMG(bunch_profile[:, bunch_profile_turn])\n",
    "    \n",
    "    plt.plot(time_profile_pred, label='Prediction')\n",
    "    # plt.plot(time_profile_target, label='Target 100 trn', marker='')\n",
    "    plt.plot(bunch_profile_target, label='Target 300 trn', marker='')\n",
    "\n",
    "    # plt.plot(np.sum(wf_s[:, :], 1), label='Target, axis=1')\n",
    "    plt.legend(fontsize=14, loc='center left')\n",
    "    # plt.xticks([], []); plt.yticks([], [])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if savefig:\n",
    "        plt.savefig(figname, dpi=100, bbox_inches='tight')\n",
    "    else:\n",
    "        plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import minMaxScaleIMG\n",
    "from utils import loadTF, calc_bin_centers, bunchProfile_TFconvolve\n",
    "\n",
    "time_scale=calc_bin_centers(0, 2.5e-9, 100)\n",
    "tf_path = './tomo_data/transfer_functions/TF_B{}.h5'\n",
    "freq_array, TF_array = loadTF(path=tf_path)\n",
    "\n",
    "def assess_model_real_data_no_table(wf, wf_id, bunch_profile, latent_pred, \n",
    "                                    ps_pred, turn, figname, savefig=False):\n",
    "    '''\n",
    "    Visual end-to-end evaluation. \n",
    "    Left: Waterfall (input)\n",
    "    Middle: Bar plot with features (latent space), real and predicted. For the evaluation of the encoder. \n",
    "    Middle bottom: PS at a given turn, real and predicted. For the evaluation of the decoder. \n",
    "    '''\n",
    "    fig, axes = plt.subplots(ncols=2, nrows=1, figsize=(8, 3),\n",
    "                             gridspec_kw={'width_ratios': [5, 5]})\n",
    "\n",
    "    wf_s = np.array(wf).reshape(128, 128).T\n",
    "    # wf_s = wf_s[zeropad:-zeropad, zeropad:-zeropad]\n",
    "    latent_pred = latent_pred.numpy().reshape((1, -1))\n",
    "\n",
    "    latent_pred_unnorm = unnormalize_params(\n",
    "        latent_pred[:, 0], latent_pred[:, 1], latent_pred[:, 2],\n",
    "        latent_pred[:, 3], latent_pred[:, 4], latent_pred[:, 5],\n",
    "        latent_pred[:, 6], normalization=normalization)\n",
    "\n",
    "    # # start with top left plot, the waterfall\n",
    "    plt.sca(axes[0])\n",
    "    plt.imshow(wf_s, cmap='jet')\n",
    "    plt.title(f'{wf_id.split(\"PROFILE_\")[1]}', fontsize=12)\n",
    "    plt.xticks([], []); plt.yticks([], [])\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "    # bottome right plot\n",
    "    plt.sca(axes[1])\n",
    "    plt.title(f'Time Projection, Turn: {turn}', fontsize=14)\n",
    "    time_profile_pred = minMaxScaleIMG(np.sum(ps_pred[:, :, 0], 0))\n",
    "    time_profile_pred = np.reshape(time_profile_pred, (128, 1))\n",
    "    # time_profile_pred = np.sum(ps_pred[:, :, 0], 0)\n",
    "    # Convolve with transfer function\n",
    "    _, time_profile_pred_tf = bunchProfile_TFconvolve(time_profile_pred[14:-14], time_scale,\n",
    "                                                   freq_array, TF_array)\n",
    "    # Pad with zeros from 100 -> 128     \n",
    "    time_profile_pred_tf = np.pad(time_profile_pred_tf[:, 0], 14)\n",
    "\n",
    "    # Which turn?\n",
    "    target_turn = int(minmax_normalize_param(\n",
    "        turn, 1, 298, target_range=(zeropad, wf.shape[1] - zeropad-1)))\n",
    "    bunch_profile_turn = int(minmax_normalize_param(\n",
    "        turn, 1, 298, target_range=(zeropad, bunch_profile.shape[1] - zeropad-1)))\n",
    "\n",
    "    # wf_turn = zeropad + int((IMG_OUTPUT_SIZE - 2 * zeropad-1) * turn/298)\n",
    "    # print(turn, wf_turn)\n",
    "    time_profile_target = minMaxScaleIMG(wf_s[target_turn, :])\n",
    "    bunch_profile_target = minMaxScaleIMG(bunch_profile[:, bunch_profile_turn])\n",
    "    # bunch_profile_target = (bunch_profile[:, bunch_profile_turn])\n",
    "\n",
    "    plt.plot(time_profile_pred, label='PRED')\n",
    "    plt.plot(time_profile_pred_tf, label='PRED \\w TF', marker='')\n",
    "\n",
    "    # plt.plot(time_profile_target, label='TRUE 100 trn', marker='')\n",
    "    plt.plot(bunch_profile_target, label='TRUE 300 trn', marker='')\n",
    "\n",
    "    # print(time_profile_pred.shape)\n",
    "    # print(bunch_profile_target.shape)\n",
    "    # print(np.abs(time_profile_pred - bunch_profile_target).shape)\n",
    "    # Also plot the diff\n",
    "    # plt.plot(np.abs(time_profile_pred - bunch_profile_target), label='DIFF')\n",
    "\n",
    "    # plt.plot(np.sum(wf_s[:, :], 1), label='Target, axis=1')\n",
    "    plt.legend(fontsize=14, loc='center left')\n",
    "    plt.xticks([], []); plt.yticks([], [])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if savefig:\n",
    "        plt.savefig(figname, dpi=100, bbox_inches='tight')\n",
    "    else:\n",
    "        plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the predictions\n",
    "out_dir = 'plots/real_data_correct_TF'\n",
    "for norm_turn in norm_turns[:]:\n",
    "    # expand turns to be equal to the number of test points\n",
    "    turn_test = np.ones(len(wf_test), dtype=np.float32)*norm_turn\n",
    "    # get the predictions\n",
    "    # start_t = time.time()\n",
    "    latent_pred, ps_pred = encDec.predictPS(wf_test, turn_test)\n",
    "    # end_t = time.time()\n",
    "    # print('Time taken:' , end_t - start_t)\n",
    "    # Now I need to plot them\n",
    "    # one directory per WF\n",
    "    for i in np.arange(len(wf_test))[:1]:\n",
    "        unnorm_turn = int(minmax_normalize_param(norm_turn, 0, 1, target_range=(1, 298)))\n",
    "        # save in a figure the turn, latents, input image, output image\n",
    "        os.makedirs(out_dir + f'/{wf_id[i]}', exist_ok=True)\n",
    "        figname = out_dir+ f'/{wf_id[i]}/time_profile_{unnorm_turn:03d}.png'\n",
    "        assess_model_real_data_no_table(wf_test[i], wf_id[i], bunch_profiles[i],\n",
    "                        latent_pred[i], ps_pred[i], \n",
    "                        unnorm_turn, figname, savefig=False)\n",
    "\n",
    "        # figname = out_dir+ f'/{wf_id[i]}/latents_time_projection_{unnorm_turn:03d}.png'\n",
    "        # assess_model_real_data(wf_test[i], wf_id[i], bunch_profiles[i],\n",
    "        #                 latent_pred[i], ps_pred[i], \n",
    "        #                 unnorm_turn, figname, savefig=True)\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import minMaxScaleIMG\n",
    "from utils import loadTF, calc_bin_centers, bunchProfile_TFconvolve\n",
    "\n",
    "time_scale = calc_bin_centers(0, 2.5e-9, 100)\n",
    "tf_path = './tomo_data/transfer_functions/TF_B{}.h5'\n",
    "freq_array, TF_array = loadTF(path=tf_path)\n",
    "\n",
    "\n",
    "def reconstruct_wf(wf, wf_id, bunch_profile, ps_pred, turns, figname, savefig=False):\n",
    "    '''\n",
    "    Visual end-to-end evaluation. \n",
    "    Left: Waterfall (input)\n",
    "    Middle: Bar plot with features (latent space), real and predicted. For the evaluation of the encoder. \n",
    "    Middle bottom: PS at a given turn, real and predicted. For the evaluation of the decoder. \n",
    "    '''\n",
    "    fig, axes = plt.subplots(ncols=3, nrows=1, figsize=(9, 3))\n",
    "\n",
    "    wf_s = minMaxScaleIMG(np.array(wf).reshape(128, 128).T)\n",
    "\n",
    "    # axis = 0 : the turns (1 ps per turn)\n",
    "    # axis = 1 : the vertical axis, the time bins\n",
    "    # axis = 2 : the horizontal axis, the energy bins\n",
    "    # axis = 3 : dummy axis, shape=1\n",
    "    wf_pred = np.sum(ps_pred, axis=1)\n",
    "    # print(wf_pred.shape)\n",
    "    wf_pred = wf_pred.reshape((100, 128))\n",
    "    _, wf_pred_tf = bunchProfile_TFconvolve((wf_pred.T)[14:-14], time_scale, freq_array, TF_array)\n",
    "    wf_pred_tf = minMaxScaleIMG(wf_pred_tf)\n",
    "\n",
    "\n",
    "    wf_pred = np.pad(wf_pred, ((14, 14), (0, 0)))\n",
    "    wf_pred_tf = np.pad(wf_pred_tf.T, ((14, 14), (14, 14)))\n",
    "    # print(wf_pred.shape)\n",
    "    \n",
    "\n",
    "    # # start with left plot, the original waterfall\n",
    "    plt.sca(axes[0])\n",
    "    plt.imshow(wf_s[14:-14, 14:-14], cmap='jet')\n",
    "    plt.title(f'{wf_id.split(\"PROFILE_\")[1]}', fontsize=12)\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # middle plot, the predicted waterfall, with TF\n",
    "    plt.sca(axes[1])\n",
    "    plt.imshow(wf_pred_tf[14:-14, 14:-14], cmap='jet')\n",
    "    plt.title(f'Predicted \\w TF', fontsize=12)\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # third plot, the difference waterfall, with TF\n",
    "    plt.sca(axes[2])\n",
    "    plt.imshow(np.abs(wf_s - wf_pred_tf)[14:-14, 14:-14], cmap='jet')\n",
    "    plt.title(f'Diff', fontsize=12)\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if savefig:\n",
    "        plt.savefig(figname, dpi=100, bbox_inches='tight')\n",
    "    else:\n",
    "        plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# normalize the turns\n",
    "# select a number of turns (31)\n",
    "selected_turns = np.linspace(1, 100, num=100, endpoint=True, dtype=np.float32)\n",
    "# print(selected_turns)\n",
    "norm_turns = minmax_normalize_param(selected_turns, np.min(selected_turns),\n",
    "                                    np.max(selected_turns),\n",
    "                                    target_range=(0, 1))\n",
    "\n",
    "# Plot the predicted WF (extracted from the PS) next to the original WF\n",
    "out_dir = 'plots/real_data_correct_TF/predicted_WFs/'\n",
    "for i in np.arange(len(wf_test)):\n",
    "    # Duplicate the wf_test multiple times\n",
    "    input_wf = np.tile(wf_test[i], (len(norm_turns), 1, 1, 1))\n",
    "    latent_pred, ps_pred = encDec.predictPS(input_wf, norm_turns)\n",
    "    \n",
    "    os.makedirs(out_dir + f'/{wf_id[i]}', exist_ok=True)\n",
    "    figname = os.path.join(out_dir, f'{wf_id[i]}.png')\n",
    "    reconstruct_wf(wf_test[i], wf_id[i], bunch_profiles[i], \n",
    "                   ps_pred, selected_turns, figname, savefig=True)\n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot evolution of latent space params per bunch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get latents for all input data\n",
    "latent_pred = encDec.encode(wf_test, unnormalize=True)\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, nrows=4, figsize=(10, 10), sharex=True)\n",
    "axes = np.ravel(axes, order='F')\n",
    "# bunch_ids = [name.split(''for name in wf_id]\n",
    "\n",
    "for lat_id in range(latent_pred.shape[1]):\n",
    "    y = latent_pred[:, lat_id]\n",
    "    var_name = var_names[loss_weights[lat_id]]\n",
    "    ax = axes[lat_id]\n",
    "    plt.sca(ax)\n",
    "    if lat_id == 0:\n",
    "        plt.title('Measurements B2_30660-31130, 2018/09/08')\n",
    "    plt.ylabel(var_name)\n",
    "    mean = np.mean(y)\n",
    "    std = np.std(y)\n",
    "    plt.plot(y, marker='x', label=f'STD: {std:.2g}')\n",
    "    plt.axhline(y=mean, label=f'AVG: {mean:.2g}', color='0', ls='--')\n",
    "    plt.xlabel('Bunch No.')\n",
    "    plt.legend(loc='upper left')\n",
    "    # plt.xticks(np.arange(len(y)))\n",
    "    plt.tight_layout()\n",
    "\n",
    "fig.delaxes(axes[-1])\n",
    "\n",
    "plt.savefig('plots/real_data_correct_TF/bunch-by-bunch-variation.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "# plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare real data to simulation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import encoder_files_to_tensors, sample_files\n",
    "# data_dir = './tomo_data/datasets_encoder_TF_16-12-22'\n",
    "data_dir = './tomo_data/datasets_encoder_TF_03-03-23'\n",
    "\n",
    "dataset_percent = 1\n",
    "num_Turns_Case = 1\n",
    "normalization = 'minmax'\n",
    "img_normalize = 'off'\n",
    "ps_normalize = 'off'\n",
    "\n",
    "# real data: wf_test\n",
    "real_x = wf_test\n",
    "real_id = wf_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize train/ test / validation paths\n",
    "ML_dir = os.path.join(data_dir, 'ML_data')\n",
    "TRAINING_PATH = os.path.join(ML_dir, 'TRAINING')\n",
    "assert os.path.exists(TRAINING_PATH)\n",
    "\n",
    "\n",
    "# First the training data\n",
    "file_names = sample_files(\n",
    "    TRAINING_PATH, dataset_percent, keep_every=num_Turns_Case)\n",
    "print(len(file_names))\n",
    "start_t = time.time()\n",
    "# read input, divide in features/ label, create tensors\n",
    "sim_x, sim_y = encoder_files_to_tensors(file_names, normalization=normalization,\n",
    "                                          img_normalize=img_normalize)\n",
    "sim_x = np.array(sim_x).reshape(-1, 128, 128)\n",
    "sim_y = np.array(sim_y)\n",
    "total_time = time.time() - start_t\n",
    "print(\n",
    "    f'Elapsed time: {total_time:.3f}, Per file: {total_time/len(file_names):.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now for every real_x, I need to find a sim_x that is as close as possible\n",
    "# One metric to use is sum(diff(x1, x2))\n",
    "min_diff_idx = [-1] * len(real_x)\n",
    "min_diff_sum = [128 * 128] * len(real_x)\n",
    "\n",
    "for i in range(len(real_x)):\n",
    "    for j in range(len(sim_x)):\n",
    "        diff_sum = np.sum(np.abs(real_x[i][14:-14,14:-14] - sim_x[j][14:-14,14:-14]))\n",
    "        if diff_sum < min_diff_sum[i]:\n",
    "            min_diff_sum[i] = diff_sum\n",
    "            min_diff_idx[i] = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predictions for real and sim data\n",
    "real_latents = encDec.encode(real_x, unnormalize=True).numpy()\n",
    "sim_latents = sim_y[min_diff_idx]\n",
    "sim_latents_unnorm = np.array(unnormalize_params(\n",
    "        sim_latents[:, 0], sim_latents[:, 1], sim_latents[:, 2],\n",
    "        sim_latents[:, 3], sim_latents[:, 4], sim_latents[:, 5],\n",
    "        sim_latents[:, 6], normalization=normalization)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 5\n",
    "# Get nrows * nrows random images\n",
    "sample = np.random.choice(np.arange(len(real_x)),\n",
    "                          size=nrows, replace=False)\n",
    "\n",
    "# Create 3x3 grid of figures\n",
    "fig, axes = plt.subplots(ncols=3, nrows=nrows, figsize=(10, 20), sharex=True)\n",
    "# axes = np.ravel(axes)\n",
    "# for i in range(len(axes)):\n",
    "for i in range(len(sample)):\n",
    "    ax = axes[i, 0]\n",
    "    plt.sca(ax)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.imshow(real_x[sample[i]], cmap='jet')\n",
    "    ax.set_title(f'{real_id[sample[i]]}')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    ax = axes[i, 1]\n",
    "    plt.sca(ax)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    # show the image\n",
    "    ax.imshow(sim_x[min_diff_idx[sample[i]]], cmap='jet')\n",
    "    # title = ','.join([f'{y:.2f}' for y in sim_y[min_diff_idx[sample[i]]]])\n",
    "    ax.set_title(f'Sim')\n",
    "\n",
    "    ax = axes[i, 2]\n",
    "    plt.sca(ax)\n",
    "    plt.axis('off')\n",
    "\n",
    "    rowLabels = [var_names[w] for w in loss_weights]\n",
    "    # cellText = [[latent] for latent in latent_pred_unnorm]\n",
    "    predicted = real_latents[sample[i]]\n",
    "    simulated = sim_latents_unnorm[sample[i]]\n",
    "    cellText = [[f'{predicted[i]:.3g}', f'{simulated[loss_weights[i]]:.3g}'] for i in range(len(predicted))]\n",
    "    plt.table(cellText=cellText, rowLabels=rowLabels,\n",
    "              colLabels=['Predicted', 'Simulation'], loc='center')\n",
    "    plt.tight_layout()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "79ab8fd01a8cec42884b8b2a5d7fb4751c5402d97e9e61d151ed5c6a6352873c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
