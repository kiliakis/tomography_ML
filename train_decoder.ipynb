{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the ML model\n",
    "\n",
    "from models import Decoder\n",
    "# from utils import load_model_data_new, normalize_params\n",
    "from utils import plot_loss, decoder_files_to_tensors\n",
    "from utils import sample_files\n",
    "\n",
    "import time\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import yaml\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "# data_dir = './tomo_data/datasets_decoder_02-12-22'\n",
    "data_dir = './tomo_data/datasets_decoder_TF_16-12-22'\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y_%m_%d_%H-%M-%S\")\n",
    "\n",
    "# Data specific\n",
    "IMG_OUTPUT_SIZE = 128\n",
    "BATCH_SIZE = 32  # 8\n",
    "latent_dim = 6  # 6 + the new VrfSPS - inten\n",
    "additional_latent_dim = 1\n",
    "\n",
    "var_names = ['turn', 'phEr', 'enEr', 'bl', 'inten', 'Vrf', 'mu', 'VrfSPS']\n",
    "\n",
    "# Train specific\n",
    "train_cfg = {\n",
    "    'epochs': 100,\n",
    "    'dense_layers': [latent_dim + additional_latent_dim, 64, 1024],\n",
    "    'filters': [32, 16, 8, 1],\n",
    "    'kernel_size': 7,\n",
    "    'strides': [2, 2],\n",
    "    'final_kernel_size': 5,\n",
    "    'activation': 'relu',\n",
    "    'final_activation': 'tanh',\n",
    "    'dropout': 0.,\n",
    "    'loss': 'mse',\n",
    "    'normalization': 'minmax',\n",
    "    'lr': 1e-3,\n",
    "    'dataset%': 0.01,\n",
    "    'loss_weights': [0, 1, 2, 3, 5, 6, 7],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize directories\n",
    "trial_dir = os.path.join('./trials/', timestamp)\n",
    "weights_dir = os.path.join(trial_dir, 'weights')\n",
    "plots_dir = os.path.join(trial_dir, 'plots')\n",
    "\n",
    "# Initialize train/ test / validation paths\n",
    "ML_dir = os.path.join(data_dir, 'ML_data')\n",
    "TRAINING_PATH = os.path.join(ML_dir, 'TRAINING')\n",
    "VALIDATION_PATH = os.path.join(ML_dir, 'VALIDATION')\n",
    "assert os.path.exists(TRAINING_PATH)\n",
    "assert os.path.exists(VALIDATION_PATH)\n",
    "\n",
    "# create the directory to store the results\n",
    "os.makedirs(trial_dir, exist_ok=True)\n",
    "os.makedirs(weights_dir, exist_ok=False)\n",
    "os.makedirs(plots_dir, exist_ok=False)\n",
    "\n",
    "# Initialize GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "device_to_use = 0\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        tf.config.experimental.set_memory_growth(gpus[device_to_use], True)\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[device_to_use],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=12*1024)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(\n",
    "            logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print('No GPU available, using the CPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First the training data\n",
    "file_names = sample_files(\n",
    "    TRAINING_PATH, train_cfg['dataset%'], keep_every=1)\n",
    "print('Number of Training files: ', len(file_names))\n",
    "x_train, y_train = decoder_files_to_tensors(\n",
    "    file_names, normalization=train_cfg['normalization'])\n",
    "\n",
    "# Repeat for validation data\n",
    "file_names = sample_files(\n",
    "    VALIDATION_PATH, train_cfg['dataset%'], keep_every=1)\n",
    "print('Number of Validation files: ', len(file_names))\n",
    "\n",
    "x_valid, y_valid = decoder_files_to_tensors(\n",
    "    file_names, normalization=train_cfg['normalization'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop column from y_train, y_valid\n",
    "x_train = tf.concat([tf.expand_dims(tf.gather(x_train, i, axis=1), axis=1)\n",
    "                     for i in train_cfg['loss_weights']], -1)\n",
    "print('x_train shape: ', x_train.shape)\n",
    "\n",
    "x_valid = tf.concat([tf.expand_dims(tf.gather(x_valid, i, axis=1), axis=1)\n",
    "                     for i in train_cfg['loss_weights']], -1)\n",
    "print('x_valid shape: ', x_valid.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# plot some of the outputs\n",
    "\n",
    "nrows = 3\n",
    "# Get nrows * nrows random images\n",
    "sample = np.random.choice(np.arange(len(x_train)), size=nrows * nrows, replace=False)\n",
    "\n",
    "samples_X = tf.gather(x_train, sample)\n",
    "samples_y = tf.gather(y_train, sample)\n",
    "\n",
    "# Create 3x3 grid of figures\n",
    "fig, axes = plt.subplots(ncols=nrows, nrows=nrows, figsize=(12, 12))\n",
    "axes = np.ravel(axes)\n",
    "for i in range(len(axes)):\n",
    "    ax = axes[i]\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    # show the image\n",
    "    ax.imshow(samples_y[i], cmap='jet')\n",
    "    # Set the label\n",
    "    title = ','.join([f'{num:.1f}' for num in samples_X[i]])\n",
    "    ax.set_title(f'{title}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model instantiation\n",
    "input_shape = (IMG_OUTPUT_SIZE, IMG_OUTPUT_SIZE, 1)\n",
    "\n",
    "decoder = Decoder(input_shape, **train_cfg)\n",
    "\n",
    "print(decoder.model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the decoder\n",
    "\n",
    "# callbacks, save the best model, and early stop if no improvement in val_loss\n",
    "stop_early = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                           patience=10, restore_best_weights=True)\n",
    "save_best = keras.callbacks.ModelCheckpoint(filepath=os.path.join(weights_dir, 'decoder.h5'),\n",
    "                                            monitor='val_loss', save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "history = decoder.model.fit(\n",
    "    x_train, y_train, epochs=train_cfg['epochs'],\n",
    "    validation_data=(x_valid, y_valid), batch_size=BATCH_SIZE,\n",
    "    callbacks=[save_best])\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(\n",
    "    f'\\n---- Training complete, epochs: {len(history.history[\"loss\"])}, total time {total_time} ----\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation loss\n",
    "print('\\n---- Plotting loss ----\\n')\n",
    "train_loss_l = np.array(history.history['loss'])\n",
    "valid_loss_l = np.array(history.history['val_loss'])\n",
    "\n",
    "plot_loss({'Training': train_loss_l, 'Validation': valid_loss_l},\n",
    "          title='Decoder Train/Validation Loss',\n",
    "          figname=os.path.join(plots_dir, 'decoder_train_valid_loss.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save file with experiment configuration\n",
    "print('\\n---- Saving a summary ----\\n')\n",
    "\n",
    "config_dict = {}\n",
    "config_dict['decoder'] = train_cfg.copy()\n",
    "\n",
    "config_dict['decoder'].update({\n",
    "    'epochs': len(history.history[\"loss\"]),\n",
    "    'min_train_loss': float(np.min(train_loss_l)),\n",
    "    'min_valid_loss': float(np.min(valid_loss_l)),\n",
    "    'total_train_time': total_time,\n",
    "    'used_gpus': len(gpus)\n",
    "})\n",
    "\n",
    "# save config_dict\n",
    "with open(os.path.join(trial_dir, 'decoder-summary.yml'), 'w') as configfile:\n",
    "    yaml.dump(config_dict, configfile, default_flow_style=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "79ab8fd01a8cec42884b8b2a5d7fb4751c5402d97e9e61d151ed5c6a6352873c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
