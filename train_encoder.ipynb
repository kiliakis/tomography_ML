{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-24 09:14:57.299477: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-24 09:14:57.299501: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# Train the ML model\n",
    "from utils import sample_files, encoder_files_to_tensors\n",
    "from utils import plot_loss, load_encoder_data\n",
    "from models import Encoder\n",
    "\n",
    "import time\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import yaml\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "num_Turns_Case = 50+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using timestamp:  2022_10_24_09-14-59\n"
     ]
    }
   ],
   "source": [
    "# Initialize parameters\n",
    "# data_dir = '/eos/kiliakis/tomo_data/datasets'\n",
    "data_dir = './tomo_data/datasets'\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y_%m_%d_%H-%M-%S\")\n",
    "print('Using timestamp: ', timestamp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data specific\n",
    "IMG_OUTPUT_SIZE = 128\n",
    "# BUFFER_SIZE = 256\n",
    "BATCH_SIZE = 128  # 8\n",
    "latent_dim = 7  # 6 + the new VrfSPS\n",
    "# additional_latent_dim = 1\n",
    "\n",
    "# Train specific\n",
    "train_cfg = {\n",
    "    'epochs': 10,\n",
    "    'dense_layers': [64, latent_dim],\n",
    "    'filters': [4, 8],\n",
    "    'cropping': [0, 0],\n",
    "    'kernel_size': 7,\n",
    "    'strides': [2, 2],\n",
    "    'activation': 'relu',\n",
    "    'pooling': None,\n",
    "    'pooling_size': [0, 0],\n",
    "    'pooling_strides': [1, 1],\n",
    "    'pooling_padding': 'valid',\n",
    "    'dropout': 0.2,\n",
    "    'loss': 'mse',\n",
    "    'lr': 1e-3,\n",
    "    'dataset%': 0.1,\n",
    "    'normalization': 'minmax',\n",
    "    'loss_weights': [1, 1, 1, 1, 1, 1, 1]\n",
    "\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-24 09:15:33.192985: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-10-24 09:15:33.193006: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-10-24 09:15:33.193020: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (kiliakis-ubuntu): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "# Initialize directories\n",
    "trial_dir = os.path.join('./trials/', timestamp)\n",
    "weights_dir = os.path.join(trial_dir, 'weights')\n",
    "plots_dir = os.path.join(trial_dir, 'plots')\n",
    "\n",
    "# Initialize train/ test / validation paths\n",
    "ML_dir = os.path.join(data_dir, 'ML_data')\n",
    "TRAINING_PATH = os.path.join(ML_dir, 'TRAINING')\n",
    "# VALIDATION_PATH = os.path.join(ML_dir, 'VALIDATION')\n",
    "assert os.path.exists(TRAINING_PATH)\n",
    "# assert os.path.exists(VALIDATION_PATH)\n",
    "\n",
    "# create the directory to store the results\n",
    "os.makedirs(trial_dir, exist_ok=True)\n",
    "os.makedirs(weights_dir, exist_ok=False)\n",
    "os.makedirs(plots_dir, exist_ok=False)\n",
    "\n",
    "# Initialize GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "device_to_use = 0\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        tf.config.experimental.set_memory_growth(gpus[device_to_use], True)\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[device_to_use],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=12*1024)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(\n",
    "            logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print('No GPU available, using the CPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training files:  195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-24 09:15:40.392400: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Input files have been read, elapsed: 0.2423388957977295 ----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_t = time.time()\n",
    "# Create the datasets\n",
    "# 1. Randomly select the training data\n",
    "file_names = sample_files(TRAINING_PATH, train_cfg['dataset%'], keep_every=num_Turns_Case)\n",
    "print('Number of Training files: ', len(file_names))\n",
    "\n",
    "x_train, y_train = encoder_files_to_tensors(\n",
    "    file_names, normalization=train_cfg['normalization'])\n",
    "'''\n",
    "# 2. Convert to tensor dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(file_names)\n",
    "\n",
    "# 3. Then map function to dataset\n",
    "# this returns pairs of tensors with shape (128, 128, 1) and (7,)\n",
    "train_dataset = train_dataset.map(lambda x: tf.py_function(\n",
    "    load_encoder_data,\n",
    "    [x, train_cfg['normalization'], True],\n",
    "    [tf.float32, tf.float32]))\n",
    "\n",
    "# 4. Ignore errors in case they appear\n",
    "train_dataset = train_dataset.apply(\n",
    "    tf.data.experimental.ignore_errors())\n",
    "\n",
    "# 6. Divide dataset in batces\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "'''\n",
    "\n",
    "# Repeat for validation data\n",
    "# file_names = sample_files(\n",
    "#     VALIDATION_PATH, train_cfg['dataset%'], keep_every=num_Turns_Case)\n",
    "# print('Number of Validation files: ', len(file_names))\n",
    "\n",
    "# x_valid, y_valid = encoder_files_to_tensors(\n",
    "#     file_names, normalization=train_cfg['normalization'])\n",
    "\n",
    "'''\n",
    "# convert to dataset\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices(file_names)\n",
    "# Then map function to dataset\n",
    "# this returns pairs of tensors with shape (128, 128, 1) and (7,)\n",
    "valid_dataset = valid_dataset.map(lambda x: tf.py_function(\n",
    "    load_encoder_data,\n",
    "    [x, train_cfg['normalization'], True],\n",
    "    [tf.float32, tf.float32]))\n",
    "# Ignore errors\n",
    "valid_dataset = valid_dataset.apply(\n",
    "    tf.data.experimental.ignore_errors())\n",
    "\n",
    "# cache the dataset\n",
    "# valid_dataset = valid_dataset.cache(\n",
    "#     os.path.join(cache_dir, 'valid_cache'))\n",
    "# batch the dataset\n",
    "valid_dataset = valid_dataset.batch(BATCH_SIZE)\n",
    "'''\n",
    "\n",
    "end_t = time.time()\n",
    "print(\n",
    "    f'\\n---- Input files have been read, elapsed: {end_t - start_t} ----\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tf.reduce_mean(y_train, 0))\n",
    "# print(tf.math.reduce_std(y_train, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# plot some of the outputs\n",
    "\n",
    "nrows = 3\n",
    "# Get nrows * nrows random images\n",
    "sample = np.random.choice(np.arange(len(x_train)),\n",
    "                          size=nrows * nrows, replace=False)\n",
    "\n",
    "samples_X = tf.gather(x_train, sample)\n",
    "samples_y = tf.gather(y_train, sample)\n",
    "\n",
    "# Create 3x3 grid of figures\n",
    "fig, axes = plt.subplots(ncols=nrows, nrows=nrows, figsize=(12, 12))\n",
    "axes = np.ravel(axes)\n",
    "for i in range(len(axes)):\n",
    "    ax = axes[i]\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    # show the image\n",
    "    ax.imshow(samples_X[i], cmap='jet')\n",
    "    # Set the label\n",
    "    title = ','.join([f'{num:.1f}' for num in samples_y[i]])\n",
    "    ax.set_title(f'{title}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Crop (Cropping2D)           (None, 128, 128, 1)       0         \n",
      "                                                                 \n",
      " CNN_1 (Conv2D)              (None, 61, 61, 4)         200       \n",
      "                                                                 \n",
      " CNN_2 (Conv2D)              (None, 28, 28, 8)         1576      \n",
      "                                                                 \n",
      " Flatten (Flatten)           (None, 6272)              0         \n",
      "                                                                 \n",
      " Dense_1 (Dense)             (None, 64)                401472    \n",
      "                                                                 \n",
      " Dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " Output (Dense)              (None, 7)                 455       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 403,703\n",
      "Trainable params: 403,703\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Model instantiation\n",
    "\n",
    "input_shape = (IMG_OUTPUT_SIZE, IMG_OUTPUT_SIZE, 1)\n",
    "\n",
    "encoder = Encoder(input_shape=input_shape, **train_cfg)\n",
    "\n",
    "print(encoder.model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the encoder\n",
    "\n",
    "# callbacks, save the best model, and early stop if no improvement in val_loss\n",
    "stop_early = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                           patience=5, restore_best_weights=True)\n",
    "save_best = keras.callbacks.ModelCheckpoint(filepath=os.path.join(weights_dir, 'encoder.h5'),\n",
    "                                            monitor='val_loss', save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1025WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.1025\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1041WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.1041\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1075WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.1075\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0909WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0909\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0936WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0936\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0953WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0953\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0817WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0817\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0821WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0821\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0782WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0782\n",
      "Epoch 10/10\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0762WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0791\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# history = encoder.model.fit(\n",
    "#     train_dataset, epochs=train_cfg['epochs'],\n",
    "#     validation_data=valid_dataset,\n",
    "#     callbacks=[stop_early, save_best])\n",
    "history = encoder.model.fit(\n",
    "    x_train, y_train, epochs=train_cfg['epochs'],\n",
    "    # validation_data=(x_valid, y_valid), \n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[stop_early, save_best])\n",
    "\n",
    "total_time = time.time() - start_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.10253168642520905, 0.10409383475780487, 0.1075415089726448, 0.09088212251663208, 0.09360166639089584, 0.09526021778583527, 0.08166756480932236, 0.0820583626627922, 0.07816998660564423, 0.07914452999830246]}\n"
     ]
    }
   ],
   "source": [
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "def my_mse(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.math.abs(y_pred - y_true), axis=0)\n",
    "\n",
    "\n",
    "y_true = np.array([[0., 0.], [1., 1.]])\n",
    "y_pred = np.array([[1., 0.5], [2., 1.5]])\n",
    "loss = keras.losses.mean_absolute_error(y_true, y_pred)\n",
    "mae2 = MyMeanAbsoluteError(reduction=keras.losses.Reduction.NONE)\n",
    "mae = keras.losses.MeanAbsoluteError(reduction=keras.losses.Reduction.NONE)\n",
    "lossv2 = mean_absolute_error(y_true, y_pred, multioutput='raw_values')\n",
    "# lossv3 = my_mse(1, y_true, y_pred)\n",
    "# print(loss)\n",
    "# print(mae(y_true, y_pred).numpy())\n",
    "print(lossv2)\n",
    "# print(mae2(y_true, y_pred).numpy())\n",
    "# lossv4 = my_mse(y_true, y_pred)\n",
    "\n",
    "print(my_mse(y_true, y_pred))\n",
    "# print(my_mse(1, y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation loss\n",
    "train_loss_l = np.array(history.history['loss'])\n",
    "valid_loss_l = np.array(history.history['val_loss'])\n",
    "\n",
    "plot_loss({'Training': train_loss_l, 'Validation': valid_loss_l},\n",
    "          title='Encoder Train/Validation Loss',\n",
    "          figname=os.path.join(plots_dir, 'encoder_train_valid_loss.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# get predictions\n",
    "y_pred = encoder.model.predict(x_valid, verbose=False)\n",
    "y_valid = np.array(y_valid)\n",
    "\n",
    "# Calculate error per variable\n",
    "mses = mean_squared_error(y_valid, y_pred, multioutput='raw_values')\n",
    "\n",
    "var_names = ['phase_error', 'energy_error',\n",
    "             'bunch_length', 'intensity', 'Volt_rf', 'mu', 'Vrf_SPS']\n",
    "# report\n",
    "print('Variable\\tMSE')\n",
    "for name, mse in zip(var_names, mses):\n",
    "    print(f'{name}:\\t{mse:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save file with experiment configuration\n",
    "config_dict = {}\n",
    "config_dict['encoder'] = train_cfg.copy()\n",
    "config_dict['encoder'].update({\n",
    "    'min_train_loss': float(np.min(train_loss_l)),\n",
    "    'min_valid_loss': float(np.min(valid_loss_l)),\n",
    "    'total_train_time': total_time,\n",
    "    'used_gpus': len(gpus)\n",
    "})\n",
    "\n",
    "# save config_dict\n",
    "with open(os.path.join(trial_dir, 'encoder-summary.yml'), 'w') as configfile:\n",
    "    yaml.dump(config_dict, configfile, default_flow_style=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 13:09:58) \n[GCC 7.5.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "79ab8fd01a8cec42884b8b2a5d7fb4751c5402d97e9e61d151ed5c6a6352873c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
