{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-15 12:19:27.022409: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-09-15 12:19:27.034934: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/kiliakis/install/lib:/usr/lib/x86_64-linux-gnu\n",
      "2022-09-15 12:19:27.034963: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# Train the ML model\n",
    "\n",
    "from models import extendedCED\n",
    "# from utils import load_model_data_new, normalize_params\n",
    "from utils import plot_loss, encoder_files_to_tensors\n",
    "import time\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import yaml\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "data_dir = '/eos/kiliakis/tomo_data/datasets'\n",
    "timestamp = datetime.now().strftime(\"%Y_%m_%d_%H-%M-%S\")\n",
    "\n",
    "# Data specific\n",
    "IMG_OUTPUT_SIZE = 128\n",
    "BUFFER_SIZE = 1000\n",
    "BATCH_SIZE = 32  # 8\n",
    "latent_dim = 7  # 6 + the new VrfSPS\n",
    "additional_latent_dim = 1\n",
    "\n",
    "# Train specific\n",
    "models_to_train = ['encoder']\n",
    "train_cfg = {\n",
    "    'encoder': {\n",
    "        'epochs': 2,\n",
    "        'lr': 2e-4,\n",
    "    },\n",
    "}\n",
    "\n",
    "# Keep only a small percentage of the entire dataset\n",
    "# for faster testing.\n",
    "dataset_keep_percent = 1\n",
    "# cnn_filters = [32, 64, 128, 256, 512, 1024]\n",
    "cnn_filters = [32]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-15 12:19:28.986466: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/kiliakis/install/lib:/usr/lib/x86_64-linux-gnu\n",
      "2022-09-15 12:19:28.986488: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-09-15 12:19:28.986503: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (sy153): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "# Initialize directories\n",
    "trial_dir = os.path.join('./trials/', timestamp)\n",
    "weights_dir = os.path.join(trial_dir, 'weights')\n",
    "plots_dir = os.path.join(trial_dir, 'plots')\n",
    "\n",
    "# Initialize train/ test / validation paths\n",
    "ML_dir = os.path.join(data_dir, 'ML_data')\n",
    "TRAINING_PATH = os.path.join(ML_dir, 'TRAINING')\n",
    "VALIDATION_PATH = os.path.join(ML_dir, 'VALIDATION')\n",
    "assert os.path.exists(TRAINING_PATH)\n",
    "assert os.path.exists(VALIDATION_PATH)\n",
    "\n",
    "# create the directory to store the results\n",
    "os.makedirs(trial_dir, exist_ok=True)\n",
    "os.makedirs(weights_dir, exist_ok=False)\n",
    "os.makedirs(plots_dir, exist_ok=False)\n",
    "\n",
    "# Initialize GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "device_to_use = 0\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        tf.config.experimental.set_memory_growth(gpus[device_to_use], True)\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[device_to_use],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=12*1024)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(\n",
    "            logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print('No GPU available, using the CPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-15 12:19:32.000378: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Create the datasets\n",
    "# First the training data\n",
    "files = glob.glob(TRAINING_PATH + '/*.pk')\n",
    "files = files[:int(len(files) * dataset_keep_percent)]\n",
    "\n",
    "# Shuffle them\n",
    "np.random.shuffle(files)\n",
    "# read input, divide in features/ label, create tensors\n",
    "x_train, y_train = encoder_files_to_tensors(files)\n",
    "\n",
    "# Then the validation data\n",
    "files = glob.glob(VALIDATION_PATH + '/*.pk')\n",
    "files = files[:int(len(files) * dataset_keep_percent)]\n",
    "\n",
    "# Shuffle them\n",
    "np.random.shuffle(files)\n",
    "# read input, divide in features/ label, create tensors\n",
    "x_valid, y_valid = encoder_files_to_tensors(files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[ 4.5072746e-01 -1.0694465e-01  1.4845453e-09  1.5647311e+11\n",
      "  6.0675392e+00  2.8910167e+00  8.5113945e+00], shape=(7,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[2.9139309e+01 5.8231640e+01 1.6700573e-10 8.4271858e+10 1.7939157e+00\n",
      " 1.1103295e+00 2.0183363e+00], shape=(7,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.reduce_mean(y_train, 0))\n",
    "print(tf.math.reduce_std(y_train, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# plot some of the outputs\n",
    "\n",
    "nrows = 3\n",
    "# Get nrows * nrows random images\n",
    "sample = np.random.choice(np.arange(len(x_train)),\n",
    "                          size=nrows * nrows, replace=False)\n",
    "\n",
    "samples_X = tf.gather(x_train, sample)\n",
    "samples_y = tf.gather(y_train, sample)\n",
    "\n",
    "# Create 3x3 grid of figures\n",
    "fig, axes = plt.subplots(ncols=nrows, nrows=nrows, figsize=(12, 12))\n",
    "axes = np.ravel(axes)\n",
    "for i in range(len(axes)):\n",
    "    ax = axes[i]\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    # show the image\n",
    "    ax.imshow(samples_X[i], cmap='jet')\n",
    "    # Set the label\n",
    "    title = ','.join([f'{num:.1f}' for num in samples_y[i]])\n",
    "    ax.set_title(f'{title}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model instantiation\n",
    "input_shape = (IMG_OUTPUT_SIZE, IMG_OUTPUT_SIZE, 1)\n",
    "\n",
    "eCED = extendedCED(latent_dim, additional_latent_dim, input_shape,\n",
    "                   filters=cnn_filters)\n",
    "\n",
    "print(eCED.encoder.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the encoder\n",
    "optimizer = tf.keras.optimizers.Adam(train_cfg['encoder']['lr'])\n",
    "\n",
    "eCED.encoder.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "# callbacks, save the best model, and early stop if no improvement in val_loss\n",
    "stop_early = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                           patience=5, restore_best_weights=True)\n",
    "save_best = keras.callbacks.ModelCheckpoint(filepath=os.path.join(weights_dir, 'encoder'),\n",
    "                                            monitor='val_loss', save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "history = eCED.encoder.fit(\n",
    "    x_train, y_train, epochs=train_cfg['encoder']['epochs'],\n",
    "    validation_data=(x_valid, y_valid), batch_size=BATCH_SIZE,\n",
    "    callbacks=[stop_early, save_best])\n",
    "\n",
    "total_time = time.time() - start_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation loss\n",
    "train_loss_l = np.array(history.history['loss'])\n",
    "valid_loss_l = np.array(history.history['val_loss'])\n",
    "\n",
    "plot_loss({'Training': train_loss_l, 'Validation': valid_loss_l},\n",
    "          title='Encoder Train/Validation Loss',\n",
    "          figname=os.path.join(plots_dir, 'encoder_train_valid_loss.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save file with experiment configuration\n",
    "config_dict = {}\n",
    "config_dict['encoder'] = {\n",
    "    'epochs': train_cfg['encoder']['epochs'],\n",
    "    'lr': train_cfg['encoder']['lr'],\n",
    "    'dataset_percent': dataset_keep_percent,\n",
    "    'cnn_filters': list(cnn_filters),\n",
    "    'min_train_loss': float(np.min(train_loss_l)),\n",
    "    'min_valid_loss': float(np.min(valid_loss_l)),\n",
    "    'total_train_time': total_time,\n",
    "    'used_gpus': len(gpus)\n",
    "}\n",
    "\n",
    "# save config_dict\n",
    "with open(os.path.join(trial_dir, 'encoder-summary.yml'), 'w') as configfile:\n",
    "    yaml.dump(config_dict, configfile, default_flow_style=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "79ab8fd01a8cec42884b8b2a5d7fb4751c5402d97e9e61d151ed5c6a6352873c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
